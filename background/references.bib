
@misc{noauthor_expressiveness_nodate,
	title = {Expressiveness in {Electronic} {Music}},
	url = {http://expressiveness.org/},
	abstract = {Exploring new ways to express yourself},
	urldate = {2017-01-30},
	journal = {Expressiveness},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/BKFMNR2G/expressiveness.org.html:text/html}
}

@misc{10thdim_imagining_2012,
	title = {Imagining the {Tenth} {Dimension} - 2012 {Version}},
	url = {https://www.youtube.com/watch?v=zqeqW3g8N2Q},
	abstract = {Thank you to Discovery Channel News for their very positive review of this video! And wow! Over TEN million views for this channel! Thanks all for your support!
To read along go to: http://imaginingthetenthdimension.blo...},
	urldate = {2017-01-30},
	author = {{10thdim}},
	year = {2012},
	keywords = {10D, 10th, 2012, Bryanton, Dimension, Einstein, ensemble, Everett, fifth, Imagining, Many, observer, omniverse, philosophy, physics, probability, quantum, space, space-time, Tenth, timelessness, ultimate, Worlds}
}

@article{james_developing_2005,
	title = {Developing a flexible and expressive realtime polyphonic wave terrain synthesis instrument based on a visual and multidimensional methodology},
	url = {http://ro.ecu.edu.au/theses/107/},
	urldate = {2017-01-31},
	author = {James, Stuart G.},
	year = {2005},
	file = {viewcontent.pdf:/Volumes/Transcend/zotero/storage/RUWAPM9W/viewcontent.pdf:application/pdf}
}

@book{baggi_music_2013,
	address = {Hoboken, N.J. : [Washington, D.C.]},
	title = {Music navigation with symbols and layers: toward content browsing with {IEEE} 1599 {XML} encoding},
	isbn = {978-0-470-59716-3},
	shorttitle = {Music navigation with symbols and layers},
	publisher = {John Wiley \& Sons ; IEEE Computer Society},
	editor = {Baggi, Denis and Haus, Goffredo},
	year = {2013},
	keywords = {Information storage and retrieval systems, Music, XML (Document markup language)}
}

@misc{anathemecollection_norman_1971,
	title = {Norman {McLaren} : {Synchromy}},
	shorttitle = {Norman {McLaren}},
	url = {https://www.youtube.com/watch?v=jiJR1ET715M},
	abstract = {graphics programming by Dean Anschultz
music by Terry Riley},
	urldate = {2017-02-01},
	author = {{AnaThemeCollection}},
	year = {1971},
	keywords = {art, courtmetrage, electronic, experiment, experimental, film, Kunst, McLaren, Music, Norman, short, visual}
}

@inproceedings{barate_real-time_2014,
	title = {Real-time {Music} {Composition} through {P}-timed {Petri} {Nets}.},
	url = {http://smc.afim-asso.org/smc-icmc-2014/images/proceedings/OS25-B02-Real-timeMusicComposition.pdf},
	urldate = {2017-02-01},
	booktitle = {{ICMC}},
	author = {Barate, Adriano and Haus, Goffredo and Ludovico, Luca A.},
	year = {2014},
	file = {ICMCSMC2014b.pdf:/Volumes/Transcend/zotero/storage/INEXVBZB/ICMCSMC2014b.pdf:application/pdf}
}

@article{baggi_neurswing:_1991,
	title = {Neurswing: an intelligent workbench for the investigation of swing in jazz},
	volume = {24},
	issn = {0018-9162},
	shorttitle = {Neurswing},
	doi = {10.1109/2.84838},
	abstract = {Neurswing is an intelligent system to investigate swing in jazz by simulating the operation of a rhythm section. From an input consisting of the harmonic grid of a standard time, it constructs a network representing musical data. At runtime the system generates and plays the music of piano, bass, and drums in real time. The user can control the performing style of the rhythm section by setting input parameters of a second, separate and asynchronous, net, which manipulates the probability of some choices. The system can simulate most aspects of a performing jazz rhythm section. It substitutes chords, bass lines, and drum licks, and has been used by practising improvisers as a didactic tool. The rules for substitution as well as the stylistic net are external to the basic system and can be configured and altered at will, allowing the user to treat the system as a workbench for experiments in the synthesis and analysis of swing.{\textless}{\textgreater}},
	number = {7},
	journal = {Computer},
	author = {Baggi, D. L.},
	month = jul,
	year = {1991},
	keywords = {Application software, Computational modeling, Computer simulation, harmonic grid, Informatics, intelligent system, intelligent workbench, jazz, knowledge based systems, Laboratories, Music, musical data, Neurswing, Project management, real-time systems, real time systems, Rhythm, stylistic net, Turning, Workstations},
	pages = {60--64},
	file = {Baggi_1991_Neurswing.pdf:/Volumes/Transcend/zotero/storage/MFCK2GVE/Baggi_1991_Neurswing.pdf:application/pdf;IEEE Xplore Abstract Record:/Volumes/Transcend/zotero/storage/VHS3T7S6/84838.html:text/html}
}

@misc{mariusz_nowostawski_jfern:_nodate,
	title = {{JFern}: demonstration of {Clojure} integration},
	shorttitle = {{JFern}},
	url = {https://www.youtube.com/watch?v=7cM9N2IkHsE},
	abstract = {This video presents how Clojure can be used inside Petri net framework called JFern. JFern is available on source forge: http://sourceforge.net/projects/jfern/   and Clojure at http://clojure.org
Writing inscriptions in dynamic lisp-like language can be more convenient than writing them in Java. Try it out.},
	urldate = {2017-02-01},
	author = {{Mariusz Nowostawski}},
	keywords = {Clojure, Java, Petri nets, programming}
}

@inproceedings{zhang_executing_2010,
	title = {Executing {Petri} net based system model},
	volume = {4},
	doi = {10.1109/ICCASM.2010.5620640},
	abstract = {Implementation in a low-level language exposes problems with the system modeling, but involves considerable development and debugging effort, particularly if the modeling problems are discovered late in the implementation and lead to significant changes being made. Implementation in a high-level language with well-defined and safe semantics could be a good solution to this issue. In this paper, Petri nets have been used to model systems. By defining rules to map Petri net to Haskell, a functional language, we get a high level implementation of the system. After executing Haskell program, we can check in the early design phase the problems that will be found in the late implementation phase. Gas station problem has been employed to illustrate our method.},
	booktitle = {2010 {International} {Conference} on {Computer} {Application} and {System} {Modeling} ({ICCASM} 2010)},
	author = {Zhang, Na and Jiang, Mingyue and Ding, Zuohua},
	month = oct,
	year = {2010},
	keywords = {computer debugging, functional language, functional languages, gas station problem, Haskell, Haskell program, high-level language, low level language, modelling, Petri net based system model, Petri nets, system debugging},
	pages = {V4--485--V4--489},
	file = {IEEE Xplore Abstract Record:/Volumes/Transcend/zotero/storage/CQZ462MW/5620640.html:text/html;Zhang et al_2010_Executing Petri net based system model.pdf:/Volumes/Transcend/zotero/storage/4G6GA96V/Zhang et al_2010_Executing Petri net based system model.pdf:application/pdf}
}

@misc{concludedfever9_geometry_nodate,
	title = {Geometry {Wars} 2: {Deadline}: 242M},
	shorttitle = {Geometry {Wars} 2},
	url = {https://www.youtube.com/watch?v=t1TAJM9HilE&feature=youtu.be},
	abstract = {Hell yeah},
	urldate = {2017-02-03},
	author = {{ConcludedFever9}},
	keywords = {concludedfever9}
}

@misc{noauthor_flow-based_2016,
	title = {Flow-based programming},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Flow-based_programming&oldid=756104969},
	abstract = {In computer programming, flow-based programming (FBP) is a programming paradigm that defines applications as networks of "black box" processes, which exchange data across predefined connections by message passing, where the connections are specified externally to the processes. These black box processes can be reconnected endlessly to form different applications without having to be changed internally. FBP is thus naturally component-oriented.
FBP is a particular form of dataflow programming based on bounded buffers, information packets with defined lifetimes, named ports, and separate definition of connections.},
	language = {en},
	urldate = {2017-02-04},
	journal = {Wikipedia},
	month = dec,
	year = {2016},
	note = {Page Version ID: 756104969},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/TBFE7UXR/index.html:text/html}
}

@misc{noauthor_modelling_nodate,
	title = {Modelling {Symbolic} {Music}: {Beyond} the {Piano} {Roll}},
	shorttitle = {Modelling {Symbolic} {Music}},
	url = {https://www.researchgate.net/publication/303821785_Modelling_Symbolic_Music_Beyond_the_Piano_Roll},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	urldate = {2017-02-06},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/E52KR9JM/303821785_Modelling_Symbolic_Music_Beyond_the_Piano_Roll.html:text/html}
}

@misc{noauthor_music_nodate,
	title = {From {Music} to {Visuals} - and {Back}. 2D {Fourier} {Transform} applied on {Music} {Piano} {Roll} {Plots}},
	url = {https://www.researchgate.net/publication/261684705_From_Music_to_Visuals_-_and_Back_2D_Fourier_Transform_applied_on_Music_Piano_Roll_Plots},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	urldate = {2017-02-06},
	file = {From Music to Visuals - and Back.pdf:/Volumes/Transcend/zotero/storage/ZVD39X99/From Music to Visuals - and Back.pdf:application/pdf}
}

@misc{noauthor_p.i..n.o.:_nodate,
	title = {P.{I}.{A}.{N}.{O}.: {Faster} {Piano} {Learning} with {Interactive} {Projection}},
	shorttitle = {P.{I}.{A}.{N}.{O}.},
	url = {https://www.researchgate.net/publication/269873077_PIANO_Faster_Piano_Learning_with_Interactive_Projection},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	urldate = {2017-02-06},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/V6F54556/269873077_PIANO_Faster_Piano_Learning_with_Interactive_Projection.html:text/html}
}

@misc{noauthor_end--end_nodate,
	title = {End-to-end music transcription using a neural network},
	url = {https://www.researchgate.net/publication/310761497_End-to-end_music_transcription_using_a_neural_network},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	urldate = {2017-02-06},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/8I88CCDF/310761497_End-to-end_music_transcription_using_a_neural_network.html:text/html}
}

@misc{noauthor_euterpea_nodate,
	title = {Euterpea {\textbar} {The} {Yale} {Haskell} {Group}},
	url = {http://haskell.cs.yale.edu/euterpea/},
	urldate = {2017-02-09},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/JCSG2JVC/euterpea.html:text/html}
}

@book{wigdor_brave_2011,
	address = {Burlington, Mass},
	title = {Brave {NUI} world: designing natural user interfaces for touch and gesture},
	isbn = {978-0-12-382231-4},
	shorttitle = {Brave {NUI} world},
	publisher = {Morgan Kaufmann},
	author = {Wigdor, Daniel and Wixon, Dennis},
	year = {2011},
	keywords = {Haptic devices, Human-computer interaction, User interfaces (Computer systems)}
}

@book{hudak_haskell_2000,
	address = {New York},
	title = {The {Haskell} school of expression: learning functional programming through multimedia},
	isbn = {978-0-521-64338-2 978-0-521-64408-2},
	shorttitle = {The {Haskell} school of expression},
	publisher = {Cambridge University Press},
	author = {Hudak, Paul},
	year = {2000},
	keywords = {Functional programming (Computer science), Multimedia systems}
}

@article{hudak_haskell_2008,
	title = {The {Haskell} {School} of {Music}},
	url = {http://www.cs.yale.edu/homes/hudak/Papers/HSoM.pdf},
	urldate = {2017-02-09},
	journal = {Yale University},
	author = {Hudak, Paul and {others}},
	year = {2008},
	file = {HSoM.pdf:/Volumes/Transcend/zotero/storage/NBUEESTP/HSoM.pdf:application/pdf}
}

@article{carpentier_predicting_nodate,
	title = {Predicting {Timbre} {Features} of {Instrument} {Sound} {Combinations}: {Application} to {Automatic} {Orchestration}},
	volume = {39},
	issn = {0929-8215},
	shorttitle = {Predicting {Timbre} {Features} of {Instrument} {Sound} {Combinations}},
	url = {https://www.academia.edu/15195420/Predicting_Timbre_Features_of_Instrument_Sound_Combinations_Application_to_Automatic_Orchestration},
	abstract = {Predicting Timbre Features of Instrument Sound Combinations: Application to Automatic Orchestration},
	urldate = {2017-02-10},
	journal = {Journal of New Music Research},
	author = {Carpentier, Grégoire and Tardieu, Damien and Harvey, Jonathan and Assayag, Gérard and Saint-James, Emmanuel},
	pages = {47--61},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/8VBN48VK/Predicting_Timbre_Features_of_Instrument_Sound_Combinations_Application_to_Automatic_Orchestrat.html:text/html}
}

@misc{noauthor_orchidee_nodate,
	title = {orchidee [{Music} {Representations} {Team}]},
	url = {http://repmus.ircam.fr/orchidee},
	urldate = {2017-02-10},
	file = {orchidee [Music Representations Team]:/Volumes/Transcend/zotero/storage/9DSCKPEM/orchidee.html:text/html}
}

@misc{noauthor_process:_nodate,
	title = {Process: {Aesthetic} {Engine} 2},
	shorttitle = {Process},
	url = {http://brutalism.rs/post/process-aesthetic-engine-2/},
	abstract = {On the web, data interpretation is defined by well-known rules. The semantics of data are defined by the system\&rsquo;s creators. Rendering is the end result of the two. But what if?In a web browser, clicking a link initiates a deluge of data, yet we as users remain mostly unaware of this process. Aesthetic Engine 2 is an application which encodes an alternative interpretation/visualization of web data, and the highly opinionated, artistic rendering of it.},
	urldate = {2017-02-10},
	journal = {BRUTALISM},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/7ZUHZB7X/process-aesthetic-engine-2.html:text/html}
}

@article{boland_visualizing_2011,
	title = {{VISUALIZING} {AND} {CONTROLLING} {SOUND} {WITH} {GRAPHICAL} {INTERFACES}},
	url = {https://www.academia.edu/2549599/VISUALIZING_AND_CONTROLLING_SOUND_WITH_GRAPHICAL_INTERFACES},
	abstract = {VISUALIZING AND CONTROLLING SOUND WITH GRAPHICAL INTERFACES},
	urldate = {2017-02-10},
	journal = {Audio Engineering Society 41st Conference: Audio for Games (2011).},
	author = {Boland, Frank and Sullivan, Liam O.},
	year = {2011},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/525XW6QG/VISUALIZING_AND_CONTROLLING_SOUND_WITH_GRAPHICAL_INTERFACES.html:text/html}
}

@article{sullivan_it_2013,
	title = {It {Looks} as it {Sounds}: {On} the use of {Images} as {Controllers} of {Audiovisual} {Material} in {Graphical} {User} {Interfaces}},
	shorttitle = {It {Looks} as it {Sounds}},
	url = {https://www.academia.edu/4431491/It_Looks_as_it_Sounds_On_the_use_of_Images_as_Controllers_of_Audiovisual_Material_in_Graphical_User_Interfaces},
	abstract = {It Looks as it Sounds: On the use of Images as Controllers of Audiovisual Material in Graphical User Interfaces},
	urldate = {2017-02-10},
	author = {Sullivan, Liam O.},
	year = {2013},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/F4VIEI8A/It_Looks_as_it_Sounds_On_the_use_of_Images_as_Controllers_of_Audiovisual_Material_in_Graphical_.html:text/html}
}

@misc{noauthor_highc_2017,
	title = {{HighC} - {Draw} your {Music}},
	url = {http://highc.org},
	abstract = {HighC is a graphical music creation and composition software tool. Its goal is to make music composition as simple and direct as sketching.},
	urldate = {2017-02-10},
	journal = {HighC - Draw your Music},
	year = {2017},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/BT94D2B3/highc.org.html:text/html}
}

@article{chen_wetbrush:_2015,
	title = {Wetbrush: {Gpu}-based 3d painting simulation at the bristle level},
	volume = {34},
	shorttitle = {Wetbrush},
	url = {http://dl.acm.org/citation.cfm?id=2818066},
	number = {6},
	urldate = {2017-02-10},
	journal = {ACM Transactions on Graphics (TOG)},
	author = {Chen, Zhili and Kim, Byungmoon and Ito, Daichi and Wang, Huamin},
	year = {2015},
	pages = {200},
	file = {Chen-2015-WB.pdf:/Volumes/Transcend/zotero/storage/RZT5NZH8/Chen-2015-WB.pdf:application/pdf}
}

@misc{diverdi_brush_2013,
	title = {A {Brush} {Stroke} {Synthesis} {Toolbox}},
	url = {https://www.researchgate.net/publication/284569392_A_Brush_Stroke_Synthesis_Toolbox},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	urldate = {2017-02-10},
	author = {Diverdi, Stephen},
	year = {2013},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/BITS3998/284569392_A_Brush_Stroke_Synthesis_Toolbox.html:text/html}
}

@article{sigursson_live_nodate,
	title = {Live {Coding} and {Csound}},
	url = {https://zenodo.org/record/50366},
	doi = {10.5281/zenodo.50366},
	abstract = {In this paper I'm going to cover a way to design a live-coding front end for Csound. My programming language of choice is Clojure, which I've used to develop Panaeolus, a live-coding program built with CsoundAPI. The aim of Panaeolus is not only to bring Csound into the world of functional programming and lisp, but also to build an extendable musical system that can create complex musical pattern, with as short and descriptive code as possible. The origin of Panaeolus dates back to April 2015 when I was using Overtone (SupercolliderAPI for Clojure) for live-coding. Initially I just added few Csound instruments into my live-coding sets, but as my preference for the acoustical qualities of Csound are greater than those of Supercollider, I decided to leave the world of Supercollider and began to develop my own live-coding environment in July that same year. At the time of this writing, Panaeolus still needs better documentation, testing and stable release. It can be found under GNU license on http://github.com/hlolli/panaeolus. Even tough I will explain concepts in this paper that apply to Clojure, I will to point out that almost identical principles apply to other programming languages, even the Csound language itself. And at the time of this writing, a short article of live-coding in the Csound language with CsoundQt front-end is scheduled for Csound Journal spring issue of 2016.},
	urldate = {2017-02-11},
	journal = {Zenodo},
	author = {Sigurðsson, Hlöðver},
	file = {Sigurðsson_Live Coding and Csound.pdf:/Volumes/Transcend/zotero/storage/NW3AJSQC/Sigurðsson_Live Coding and Csound.pdf:application/pdf;Snapshot:/Volumes/Transcend/zotero/storage/B3RV52B5/50366.html:text/html}
}

@misc{noauthor_odesi_nodate,
	title = {Odesi 2.0},
	url = {http://welcome.odesi.com/yw},
	abstract = {Odesi is a digital download, so the link will arrive immediately. It comes with a 30-day money back guarantee because we love our customers and want to make sure you're always happy.Get your Odesi (Windows + Mac download) for just \$49 US:},
	urldate = {2017-02-18},
	journal = {Odesi 2.0},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/25PG4QG9/yw.html:text/html}
}

@misc{sonic_writing_sally_2016,
	title = {Sally {Jane} {Norman}: {New} {Notations} and {Embodied} {Experience}},
	shorttitle = {Sally {Jane} {Norman}},
	url = {https://www.youtube.com/watch?v=-pOJPBfOpNw&list=PLmT6FPbZVeEVHc6aelAon5tPyBI7SYGW_&index=4},
	abstract = {Sally Jane Norman presents 'New Notations and Embodied Experience' at the New Notations Symposium held at IRCAM in Paris during September 2016.},
	urldate = {2017-02-18},
	author = {{Sonic Writing}},
	year = {2016}
}

@misc{noauthor_digital_nodate,
	title = {Digital {Brushes}},
	url = {http://digitalbrushes.tumblr.com/?og=1},
	abstract = {Maintainer: Eyecager/Amber Blade Jones Email me about broken links here: amberbladejones@gmail.com},
	urldate = {2017-02-19},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/P8WIF2JP/digitalbrushes.tumblr.com.html:text/html}
}

@misc{noauthor_why_nodate,
	title = {Why expression},
	url = {http://www.rogerlinndesign.com/why-expression.html},
	urldate = {2017-02-19},
	file = {Why expression:/Volumes/Transcend/zotero/storage/K8IKZPPF/why-expression.html:text/html}
}

@misc{noauthor_music_nodate-1,
	title = {The {Music} {Room}: {Unique} {Instruments}, {Inspiring} {Spaces} in {VR}},
	url = {http://musicroomvr.com/},
	urldate = {2017-02-19},
	file = {The Music Room\: Unique Instruments, Inspiring Spaces in VR:/Volumes/Transcend/zotero/storage/JATGHP97/musicroomvr.com.html:text/html}
}

@misc{noauthor_making_2016,
	title = {Making {Music} {In} {VR}: '{The} {Music} {Room},' {Hands} {On}},
	shorttitle = {Making {Music} {In} {VR}},
	url = {http://www.tomshardware.com/news/music-room-chroma-coda-vr,32783.html},
	abstract = {To fully understand what a laser harp is (and how it works), we spent some time with the SteamVR version of "The Music Room" to see just what we could do with a virtual MIDI studio at our disposal.},
	urldate = {2017-02-19},
	journal = {Tom's Hardware},
	month = sep,
	year = {2016},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/RGJI6M35/music-room-chroma-coda-vr,32783.html:text/html}
}

@misc{noauthor_draw_2016,
	title = {Draw {Collaboratively} {In} {VR}: {Google} {Experimenting} {With} {Multiplayer} {Tilt} {Brush}},
	shorttitle = {Draw {Collaboratively} {In} {VR}},
	url = {http://www.tomshardware.com/news/google-tilt-brush-vr-game,32788.html},
	abstract = {Google is always experimenting with new ideas for Tilt Brush. Multiplayer is one of the latest, and more promising, innovations. It just may see a public release.},
	urldate = {2017-02-19},
	journal = {Tom's Hardware},
	month = sep,
	year = {2016},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/FKZTFAB2/google-tilt-brush-vr-game,32788.html:text/html}
}

@misc{google_vr_tilt_nodate,
	title = {Tilt {Brush}: {Jolly} {Bones}},
	shorttitle = {Tilt {Brush}},
	url = {https://www.youtube.com/watch?v=YobyXs8osxM},
	abstract = {Google has been working closely with more than 60 artists to help them explore their style in virtual reality as part of the Tilt Brush Artist in Residence program (AiR). Coming from a wide range of disciplines, these graffiti artists, painters, illustrators, graphic designers, dancers, concept artists, creative technologists and cartoonists have all brought their passion and talent to create some amazing art with Tilt Brush.

Learn more and view their work at www.tiltbrush.com/air},
	urldate = {2017-02-19},
	author = {{Google VR}},
	keywords = {htc vive, pirate, tilt brush, vr}
}

@misc{noauthor_image--image_nodate,
	title = {Image-to-{Image} {Demo} - {Affine} {Layer}},
	url = {http://affinelayer.com/pixsrv/},
	urldate = {2017-02-23},
	file = {Image-to-Image Demo - Affine Layer:/Volumes/Transcend/zotero/storage/XXBZVEMZ/pixsrv.html:text/html}
}

@misc{noauthor_beholder.jpg_nodate,
	title = {beholder.jpg (691×398)},
	url = {http://affinelayer.com/pixsrv/beholder.jpg},
	urldate = {2017-02-23},
	file = {beholder.jpg (691×398):/Volumes/Transcend/zotero/storage/BRTFMDIC/beholder.html:text/html}
}

@misc{noauthor_r-e-s-t_nodate,
	title = {R-{E}-{S}-{T} and {Composition}: {Silence}, {Breath} and aah ? [{Gap}] {Musical} {Rest}},
	shorttitle = {R-{E}-{S}-{T} and {Composition}},
	url = {https://www.researchgate.net/publication/308707387_R-E-S-T_and_Composition_Silence_Breath_and_aah_Gap_Musical_Rest},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	urldate = {2017-02-23},
	file = {R-E-S-T and Composition.pdf:/Volumes/Transcend/zotero/storage/6W4Z82WX/R-E-S-T and Composition.pdf:application/pdf}
}

@misc{popova_100_2012,
	title = {100 {Diagrams} {That} {Changed} the {World}},
	url = {https://www.brainpickings.org/2012/12/21/100-diagrams-that-changed-the-world/},
	abstract = {A visual history of human sensemaking, from cave paintings to the world wide web.},
	urldate = {2017-02-28},
	journal = {Brain Pickings},
	author = {Popova, Maria},
	month = dec,
	year = {2012},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/IFPHAD68/100-diagrams-that-changed-the-world.html:text/html}
}

@misc{noauthor_edward_nodate,
	title = {Edward {Tufte} forum: {Display} of musical structure},
	url = {https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000MB},
	urldate = {2017-02-28},
	file = {Edward Tufte forum\: Display of musical structure:/Volumes/Transcend/zotero/storage/5MTHWT3H/q-and-a-fetch-msg.html:text/html}
}

@misc{noauthor_macroscope_nodate,
	title = {Macroscope {Manifesto} 02-27-02},
	url = {http://radio-weblogs.com/0104369/stories/2002/04/09/macroscope022702.htm#_edn9},
	urldate = {2017-02-28},
	file = {Macroscope Manifesto 02-27-02:/Volumes/Transcend/zotero/storage/N4P7NIHV/macroscope022702.html:text/html}
}

@misc{noauthor_visual_nodate,
	title = {Visual displays},
	url = {https://www.pinterest.com/pin/104356916335417618/},
	abstract = {Music score with dance notation},
	urldate = {2017-02-28},
	journal = {Pinterest},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/X6BTHTQ4/104356916335417618.html:text/html}
}

@misc{noauthor_graphic_2013,
	title = {Graphic music scores - in pictures},
	url = {http://www.theguardian.com/music/gallery/2013/oct/04/graphic-music-scores-in-pictures},
	abstract = {How do you play a picture? Composers and artists from John Cage to Brian Eno have experimented with notation to create extraordinary visual scores that rival the best contemporary art. Here Notation 21's Theresa Sauer introduces a selection of her favourites.},
	urldate = {2017-02-28},
	journal = {the Guardian},
	month = oct,
	year = {2013},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/DJARBDHG/graphic-music-scores-in-pictures.html:text/html}
}

@misc{noauthor_edward_nodate-1,
	title = {Edward {Tufte} forum: {Music} {Animation} {Machine}},
	url = {https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=00005y},
	urldate = {2017-02-28},
	file = {Edward Tufte forum\: Music Animation Machine:/Volumes/Transcend/zotero/storage/SXQGK2WU/q-and-a-fetch-msg.html:text/html}
}

@misc{noauthor_music_nodate-2,
	title = {Music {Animation} {Machine}},
	url = {http://www.musanim.com/},
	urldate = {2017-02-28},
	file = {Music Animation Machine:/Volumes/Transcend/zotero/storage/R3U49ZE2/www.musanim.com.html:text/html}
}

@misc{noauthor_conductor_nodate,
	title = {Conductor {Program} (computer-mediated performance)},
	url = {http://www.musanim.com/tapper/},
	urldate = {2017-02-28},
	file = {Conductor Program (computer-mediated performance):/Volumes/Transcend/zotero/storage/7V732SMG/tapper.html:text/html}
}

@misc{ethan_visualizing_2011,
	title = {Visualizing music},
	url = {http://www.ethanhein.com/wp/2011/visualizing-music/},
	abstract = {Update: check out my masters thesis, a radial drum machine. Specifically, see the section on visualizing rhythm. See also a more scholarly review of the literature on visualization and music educat…},
	urldate = {2017-02-28},
	journal = {The Ethan Hein Blog},
	author = {{Ethan}},
	month = oct,
	year = {2011},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/DGD4R9VZ/visualizing-music.html:text/html}
}

@misc{ethan_affordances_2017,
	title = {Affordances and {Constraints}},
	url = {http://www.ethanhein.com/wp/2017/affordances-and-constraints/},
	abstract = {Note-taking for User Experience Design with June Ahn Don Norman discusses affordances and constraints in The Design of Everyday Things, Chapter Four: Knowing What To Do. User experience design is e…},
	urldate = {2017-02-28},
	journal = {The Ethan Hein Blog},
	author = {{Ethan}},
	month = jan,
	year = {2017},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/FHF2XGWA/affordances-and-constraints.html:text/html}
}

@misc{noauthor_walrus_nodate,
	title = {Walrus - {Graph} {Visualization} {Tool}},
	url = {http://www.caida.org/tools/visualization/walrus/},
	urldate = {2017-02-28},
	file = {Walrus - Graph Visualization Tool:/Volumes/Transcend/zotero/storage/C2KJ7W66/walrus.html:text/html}
}

@misc{noauthor_noneuclid_nodate,
	title = {{NonEuclid} - {Hyperbolic} {Geometry} {Article} and {Javascript} {Software}},
	url = {http://cs.unm.edu/~joel/NonEuclid/},
	urldate = {2017-02-28},
	file = {NonEuclid - Hyperbolic Geometry Article and Javascript Software:/Volumes/Transcend/zotero/storage/FUFA4QVN/NonEuclid.html:text/html}
}

@misc{ethan_affordances_2017-1,
	title = {Affordances and {Constraints}},
	url = {http://www.ethanhein.com/wp/2017/affordances-and-constraints/},
	abstract = {Note-taking for User Experience Design with June Ahn Don Norman discusses affordances and constraints in The Design of Everyday Things, Chapter Four: Knowing What To Do. User experience design is e…},
	urldate = {2017-02-28},
	journal = {The Ethan Hein Blog},
	author = {{Ethan}},
	month = jan,
	year = {2017},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/6KQ7MZKX/affordances-and-constraints.html:text/html}
}

@misc{noauthor_cubic_nodate,
	title = {Cubic {Limit} ← {Stream} ← {MuDA} ↵},
	url = {http://muda.co/stream/cubic.php},
	abstract = {Cubic Limit by digital arts pioneer Manfred Mohr.},
	urldate = {2017-02-28},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/WIJW5WNS/cubic.html:text/html}
}

@misc{noauthor_don_nodate,
	title = {Don {Knuth}'s {Home} {Page}},
	url = {http://www-cs-faculty.stanford.edu/~uno/},
	urldate = {2017-02-28},
	file = {Don Knuth's Home Page:/Volumes/Transcend/zotero/storage/V23768Q8/~uno.html:text/html}
}

@misc{noauthor_journal_nodate,
	title = {Journal on the {Art} of {Record} {Production} » {Beyond} {Skeuomorphism}: {The} {Evolution} of {Music} {Production} {Software} {User} {Interface} {Metaphors}},
	url = {http://arpjournal.com/beyond-skeuomorphism-the-evolution-of-music-production-software-user-interface-metaphors-2/},
	urldate = {2017-02-28},
	file = {Journal on the Art of Record Production » Beyond Skeuomorphism\: The Evolution of Music Production Software User Interface Metaphors:/Volumes/Transcend/zotero/storage/RJVM9UV3/beyond-skeuomorphism-the-evolution-of-music-production-software-user-interface-metaphors-2.html:text/html}
}

@misc{noauthor_harmony_nodate,
	title = {Harmony {Explained}: {Progress} {Towards} {A} {Scientific} {Theory} of {Music}},
	url = {https://arxiv.org/html/1202.4212v1},
	urldate = {2017-03-01},
	file = {Harmony Explained\: Progress Towards A Scientific Theory of Music:/Volumes/Transcend/zotero/storage/F3APNUQ3/1202.html:text/html}
}

@misc{noauthor_velato:_2009,
	title = {Velato: {What} if {Musical} {Notes} {Had} {Their} {Own} {Programming} {Language}?},
	shorttitle = {Velato},
	url = {http://cdm.link/2009/01/verlato-what-if-musical-notes-had-their-own-programming-language/},
	abstract = {Photo (CC) Quinn Dombrowski. Composing music is not unlike programming – and either, at their best, can be expressive. In the early days of IT (before “IT” was even a term), many computer programmers came from a musical background. (And even early in the computer age, there was more call for software than symphonies – and more pay.) But what if you could program music easily, using musical syntax in a programming language? That’s the question asked by languages like Velato. The commands actually aren’t as esoteric as you might expect; they include references to standard pitch and commands like ...},
	urldate = {2017-03-01},
	journal = {CDM Create Digital Music},
	month = jan,
	year = {2009},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/RXPK4J24/verlato-what-if-musical-notes-had-their-own-programming-language.html:text/html}
}

@misc{noauthor_velato_nodate,
	title = {Velato},
	url = {http://velato.net/},
	urldate = {2017-03-01},
	file = {Velato:/Volumes/Transcend/zotero/storage/66KQ2ZUU/velato.net.html:text/html}
}

@misc{noauthor_daphne_nodate,
	title = {Daphne {Oram} documentary - {Wee} {Have} {Also} {Sound}-{Houses} - {YouTube}},
	url = {https://www.youtube.com/},
	abstract = {Enjoy the videos and music you love, upload original content and share it all with friends, family and the world on YouTube.},
	urldate = {2017-03-05},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/R3QQZQ9U/watch.html:text/html}
}

@misc{noauthor_generative_2016,
	title = {Generative theory of tonal music},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Generative_theory_of_tonal_music&oldid=732219979},
	abstract = {A generative theory of tonal music (GTTM) is a theory of music conceived by American composer and music theorist Fred Lerdahl and American linguist Ray Jackendoff and presented in the 1983 book of the same title. It constitutes a "formal description of the musical intuitions of a listener who is experienced in a musical idiom" with the aim of illuminating the unique human capacity for musical understanding.
The collaboration between Lerdahl and Jackendoff was inspired by Leonard Bernstein's 1973 Charles Eliot Norton Lectures at Harvard University, wherein he called for researchers to uncover a musical grammar that could explain the human musical mind in a scientific manner comparable to Noam Chomsky's revolutionary transformational or generative grammar.
Unlike the major methodologies of music analysis that preceded it, GTTM construes the mental procedures under which the listener constructs an unconscious understanding of music, and uses these tools to illuminate the structure of individual compositions. The theory has been influential, spurring further work by its authors and other researchers in the fields of music theory, music cognition and cognitive musicology.},
	language = {en},
	urldate = {2017-03-11},
	journal = {Wikipedia},
	month = jul,
	year = {2016},
	note = {Page Version ID: 732219979},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/65USFBMV/index.html:text/html}
}

@misc{noauthor_music_nodate-3,
	title = {Music {Notation} {Style} {Guide}: {Composition}: {Departments}, {Offices} and {Services}: {Jacobs} {School} of {Music}: {Indiana} {University} {Bloomington}},
	url = {http://www.music.indiana.edu/departments/academic/composition/style-guide/},
	urldate = {2017-03-11},
	file = {Music Notation Style Guide\: Composition\: Departments, Offices and Services\: Jacobs School of Music\: Indiana University Bloomington:/Volumes/Transcend/zotero/storage/UWWUQNJM/style-guide.html:text/html}
}

@book{noauthor_visual_nodate-1,
	title = {Visual {Language} {Theory} {\textbar} {Kim} {Marriott} {\textbar} {Springer}},
	url = {http://www.springer.com/gp/book/9780387983677},
	abstract = {Kim Marriott Bernd Meyer Communication is one of the hallmarks of humans. When we think of hu­ man communication, most people first think of spoken and...},
	urldate = {2017-03-11},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/XXIMDPJV/9780387983677.html:text/html}
}

@misc{noauthor_rastrum_2016,
	title = {Rastrum},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Rastrum&oldid=747091708},
	abstract = {A rastrum (or raster) is a five-pointed writing implement used in music manuscripts to draw parallel staff lines when drawn horizontally across a blank piece of sheet music. The word "raster" is derived from the Latin for "rake". Rastra were used to draw lines on paper that had not been pre-ruled, and were widely used in Europe until printed staff paper became cheap and common in the nineteenth century. Some rastra are able to draw more than one staff at a time. Rastrology, the study of the use of the rastrum, is a branch of music manuscript studies that uses information about the rastrum to help find the date and provenance of musical materials.},
	language = {en},
	urldate = {2017-03-11},
	journal = {Wikipedia},
	month = oct,
	year = {2016},
	note = {Page Version ID: 747091708},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/8JQZSBNA/index.html:text/html}
}

@article{noauthor_implementing_2007,
	title = {Implementing synthesis control using timbral adjectives},
	volume = {121},
	issn = {0001-4966},
	url = {http://asa.scitation.org/doi/10.1121/1.4782089},
	doi = {10.1121/1.4782089},
	number = {5},
	urldate = {2017-03-13},
	journal = {The Journal of the Acoustical Society of America},
	month = may,
	year = {2007},
	pages = {3119--3120},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/UKTDHIS2/1.html:text/html}
}

@article{elliott_acoustic_2013,
	title = {Acoustic structure of the five perceptual dimensions of timbre in orchestral instrument tones},
	volume = {133},
	issn = {00014966},
	url = {http://elib.tcd.ie/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=a9h&AN=84623393&site=eds-live&scope=site},
	doi = {10.1121/1.4770244},
	abstract = {Attempts to relate the perceptual dimensions of timbre to quantitative acoustical dimensions have been tenuous, leading to claims that timbre is an emergent property, if measurable at all. Here, a three-pronged analysis shows that the timbre space of sustained instrument tones occupies 5 dimensions and that a specific combination of acoustic properties uniquely determines gestalt perception of timbre. Firstly, multidimensional scaling (MDS) of dissimilarity judgments generated a perceptual timbre space in which 5 dimensions were cross-validated and selected by traditional model comparisons. Secondly, subjects rated tones on semantic scales. A discriminant function analysis (DFA) accounting for variance of these semantic ratings across instruments and between subjects also yielded 5 significant dimensions with similar stimulus ordination. The dimensions of timbre space were then interpreted semantically by rotational and reflectional projection of the MDS solution into two DFA dimensions. Thirdly, to relate this final space to acoustical structure, the perceptual MDS coordinates of each sound were regressed with its joint spectrotemporal modulation power spectrum. Sound structures correlated significantly with distances in perceptual timbre space. Contrary to previous studies, most perceptual timbre dimensions are not the result of purely temporal or spectral features but instead depend on signature spectrotemporal patterns.},
	number = {1},
	urldate = {2017-03-13},
	journal = {Journal of the Acoustical Society of America},
	author = {Elliott, Taffeta M. and Hamilton, Liberty S. and Theunissen, Frédéric E.},
	month = jan,
	year = {2013},
	keywords = {GESTALT psychology, MUSIC -- Acoustics \& physics, MUSICAL groups, ORCHESTRA, TONE color (Music theory)},
	pages = {389--404},
	file = {Elliott et al_2013_Acoustic structure of the five perceptual dimensions of timbre in orchestral.pdf:/Volumes/Transcend/zotero/storage/7MGABUZW/Elliott et al_2013_Acoustic structure of the five perceptual dimensions of timbre in orchestral.pdf:application/pdf}
}

@misc{noauthor_image_nodate,
	title = {image processing - 2D {Shape} recognition algorithm - looking for guidance - {Stack} {Overflow}},
	url = {http://stackoverflow.com/questions/25148136/2d-shape-recognition-algorithm-looking-for-guidance},
	urldate = {2017-03-14},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/J25E82TC/2d-shape-recognition-algorithm-looking-for-guidance.html:text/html}
}

@misc{noauthor_supervised_nodate,
	title = {Supervised {Learning} {Workflow} and {Algorithms} - {MATLAB} \& {Simulink} - {MathWorks} {United} {Kingdom}},
	url = {http://uk.mathworks.com/help/stats/supervised-learning-machine-learning-workflow-and-algorithms.html?requestedDomain=nl.mathworks.com},
	urldate = {2017-03-14},
	file = {Supervised Learning Workflow and Algorithms - MATLAB & Simulink - MathWorks United Kingdom:/Volumes/Transcend/zotero/storage/INE86A34/supervised-learning-machine-learning-workflow-and-algorithms.html:text/html}
}

@misc{noauthor_adaptive_nodate,
	title = {The {Adaptive} {Hybrid} {Cursor}: {A} {Pressure}-{Based} {Target} {Selection} {Technique} for {Pen}-{Based} {User} {Interfaces}},
	shorttitle = {The {Adaptive} {Hybrid} {Cursor}},
	url = {https://www.researchgate.net/publication/221054333_The_Adaptive_Hybrid_Cursor_A_Pressure-Based_Target_Selection_Technique_for_Pen-Based_User_Interfaces},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	urldate = {2017-03-15},
	journal = {ResearchGate},
	file = {The Adaptive Hybrid Cursor.pdf:/Volumes/Transcend/zotero/storage/DQ5X4JCP/The Adaptive Hybrid Cursor.pdf:application/pdf}
}

@misc{markou_black_nodate,
	title = {The {Black} {Magic} of {Deep} {Learning} - {Tips} and {Tricks} for the practitioner},
	url = {http://nmarkou.blogspot.com/2017/02/the-black-magic-of-deep-learning-tips.html},
	abstract = {I've been using Deep Learning and Deep Belief Networks since 2013.  I was involved in a green field project and I was in charge of deciding...},
	urldate = {2017-03-18},
	author = {Markou, Nikolas},
	file = {Snapshot:/Volumes/Transcend/zotero/storage/PBXPBSM7/the-black-magic-of-deep-learning-tips.html:text/html}
}