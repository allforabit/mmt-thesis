
@misc{_expressiveness_????,
  title = {Expressiveness in {{Electronic Music}}},
  abstract = {Exploring new ways to express yourself},
  timestamp = {2017-01-30T16:09:25Z},
  urldate = {2017-01-30},
  howpublished = {\url{http://expressiveness.org/}},
  journal = {Expressiveness},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/BKFMNR2G/expressiveness.org.html:text/html},
  groups = {mmt-thesis}
}

@misc{10thdim_imagining_2012,
  title = {Imagining the {{Tenth Dimension}} - 2012 {{Version}}},
  abstract = {Thank you to Discovery Channel News for their very positive review of this video! And wow! Over TEN million views for this channel! Thanks all for your support!
To read along go to: http://imaginingthetenthdimension.blo...},
  timestamp = {2017-02-01T14:21:42Z},
  urldate = {2017-01-30},
  author = {{10thdim}},
  year = {2012},
  keywords = {10D,10th,2012,Bryanton,Dimension,Einstein,ensemble,Everett,fifth,Imagining,Many,observer,omniverse,philosophy,physics,probability,quantum,space,space-time,Tenth,timelessness,ultimate,Worlds},
  groups = {mmt-thesis}
}

@article{james_developing_2005,
  title = {Developing a Flexible and Expressive Realtime Polyphonic Wave Terrain Synthesis Instrument Based on a Visual and Multidimensional Methodology},
  timestamp = {2017-01-31T12:00:55Z},
  urldate = {2017-01-31},
  author = {James, Stuart G.},
  year = {2005},
  file = {viewcontent.pdf:/Volumes/Transcend/zotero/storage/RUWAPM9W/viewcontent.pdf:application/pdf},
  groups = {mmt-thesis}
}

@book{baggi_music_2013,
  address = {Hoboken, N.J. : [Washington, D.C.]},
  title = {Music Navigation with Symbols and Layers: Toward Content Browsing with {{IEEE}} 1599 {{XML}} Encoding},
  isbn = {978-0-470-59716-3},
  lccn = {ML74.3 .M87 2013},
  shorttitle = {Music Navigation with Symbols and Layers},
  timestamp = {2017-01-31T12:20:13Z},
  publisher = {{John Wiley \& Sons ; IEEE Computer Society}},
  editor = {Baggi, Denis and Haus, Goffredo},
  year = {2013},
  keywords = {Information storage and retrieval systems,Music,XML (Document markup language)},
  groups = {mmt-thesis}
}

@misc{anathemecollection_norman_1971,
  title = {Norman {{McLaren}} : {{Synchromy}}},
  shorttitle = {Norman {{McLaren}}},
  abstract = {graphics programming by Dean Anschultz
music by Terry Riley},
  timestamp = {2017-02-01T14:23:46Z},
  urldate = {2017-02-01},
  author = {{AnaThemeCollection}},
  year = {1971},
  keywords = {art,courtmetrage,electronic,experiment,experimental,film,Kunst,McLaren,Music,Norman,short,visual},
  groups = {mmt-thesis}
}

@inproceedings{barate_real-time_2014,
  title = {Real-Time {{Music Composition}} through {{P}}-Timed {{Petri Nets}}.},
  timestamp = {2017-02-01T17:05:07Z},
  urldate = {2017-02-01},
  booktitle = {{{ICMC}}},
  author = {Barate, Adriano and Haus, Goffredo and Ludovico, Luca A.},
  year = {2014},
  file = {ICMCSMC2014b.pdf:/Volumes/Transcend/zotero/storage/INEXVBZB/ICMCSMC2014b.pdf:application/pdf},
  groups = {mmt-thesis}
}

@article{baggi_neurswing:_1991,
  title = {Neurswing: An Intelligent Workbench for the Investigation of Swing in Jazz},
  volume = {24},
  issn = {0018-9162},
  shorttitle = {Neurswing},
  doi = {10.1109/2.84838},
  abstract = {Neurswing is an intelligent system to investigate swing in jazz by simulating the operation of a rhythm section. From an input consisting of the harmonic grid of a standard time, it constructs a network representing musical data. At runtime the system generates and plays the music of piano, bass, and drums in real time. The user can control the performing style of the rhythm section by setting input parameters of a second, separate and asynchronous, net, which manipulates the probability of some choices. The system can simulate most aspects of a performing jazz rhythm section. It substitutes chords, bass lines, and drum licks, and has been used by practising improvisers as a didactic tool. The rules for substitution as well as the stylistic net are external to the basic system and can be configured and altered at will, allowing the user to treat the system as a workbench for experiments in the synthesis and analysis of swing.$<$$>$},
  timestamp = {2017-02-01T17:27:34Z},
  number = {7},
  journal = {Computer},
  author = {Baggi, D. L.},
  month = jul,
  year = {1991},
  keywords = {Application software,Computational modeling,Computer simulation,harmonic grid,Informatics,intelligent system,intelligent workbench,jazz,knowledge based systems,Laboratories,Music,musical data,Neurswing,Project management,real-time systems,real time systems,Rhythm,stylistic net,Turning,Workstations},
  pages = {60--64},
  file = {Baggi_1991_Neurswing.pdf:/Volumes/Transcend/zotero/storage/MFCK2GVE/Baggi_1991_Neurswing.pdf:application/pdf;IEEE Xplore Abstract Record:/Volumes/Transcend/zotero/storage/VHS3T7S6/84838.html:text/html},
  groups = {mmt-thesis}
}

@misc{mariusz_nowostawski_jfern:_????,
  title = {{{JFern}}: Demonstration of {{Clojure}} Integration},
  shorttitle = {{{JFern}}},
  abstract = {This video presents how Clojure can be used inside Petri net framework called JFern. JFern is available on source forge: http://sourceforge.net/projects/jfern/   and Clojure at http://clojure.org
Writing inscriptions in dynamic lisp-like language can be more convenient than writing them in Java. Try it out.},
  timestamp = {2017-02-01T17:28:16Z},
  urldate = {2017-02-01},
  author = {{Mariusz Nowostawski}},
  keywords = {Clojure,Java,Petri nets,programming},
  groups = {mmt-thesis}
}

@inproceedings{zhang_executing_2010,
  title = {Executing {{Petri}} Net Based System Model},
  volume = {4},
  doi = {10.1109/ICCASM.2010.5620640},
  abstract = {Implementation in a low-level language exposes problems with the system modeling, but involves considerable development and debugging effort, particularly if the modeling problems are discovered late in the implementation and lead to significant changes being made. Implementation in a high-level language with well-defined and safe semantics could be a good solution to this issue. In this paper, Petri nets have been used to model systems. By defining rules to map Petri net to Haskell, a functional language, we get a high level implementation of the system. After executing Haskell program, we can check in the early design phase the problems that will be found in the late implementation phase. Gas station problem has been employed to illustrate our method.},
  timestamp = {2017-02-01T17:43:09Z},
  booktitle = {2010 {{International Conference}} on {{Computer Application}} and {{System Modeling}} ({{ICCASM}} 2010)},
  author = {Zhang, Na and Jiang, Mingyue and Ding, Zuohua},
  month = oct,
  year = {2010},
  keywords = {computer debugging,functional language,functional languages,gas station problem,Haskell,Haskell program,high-level language,low level language,modelling,Petri net based system model,Petri nets,system debugging},
  pages = {V4--485--V4--489},
  file = {Zhang et al_2010_Executing Petri net based system model.pdf:/Volumes/Transcend/zotero/storage/4G6GA96V/Zhang et al_2010_Executing Petri net based system model.pdf:application/pdf;IEEE Xplore Abstract Record:/Volumes/Transcend/zotero/storage/CQZ462MW/5620640.html:text/html},
  groups = {mmt-thesis}
}

@misc{concludedfever9_geometry_????,
  title = {Geometry {{Wars}} 2: {{Deadline}}: {{242M}}},
  shorttitle = {Geometry {{Wars}} 2},
  abstract = {Hell yeah},
  timestamp = {2017-02-03T20:24:08Z},
  urldate = {2017-02-03},
  author = {{ConcludedFever9}},
  keywords = {concludedfever9},
  groups = {mmt-thesis}
}

@misc{_flow-based_2016,
  title = {Flow-Based Programming},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In computer programming, flow-based programming (FBP) is a programming paradigm that defines applications as networks of "black box" processes, which exchange data across predefined connections by message passing, where the connections are specified externally to the processes. These black box processes can be reconnected endlessly to form different applications without having to be changed internally. FBP is thus naturally component-oriented.
FBP is a particular form of dataflow programming based on bounded buffers, information packets with defined lifetimes, named ports, and separate definition of connections.},
  language = {en},
  timestamp = {2017-02-04T13:11:19Z},
  urldate = {2017-02-04},
  journal = {Wikipedia},
  month = dec,
  year = {2016},
  note = {Page Version ID: 756104969},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/TBFE7UXR/index.html:text/html},
  groups = {mmt-thesis}
}

@misc{_modelling_????,
  title = {Modelling {{Symbolic Music}}: {{Beyond}} the {{Piano Roll}}},
  shorttitle = {Modelling {{Symbolic Music}}},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-02-06T21:57:26Z},
  urldate = {2017-02-06},
  howpublished = {\url{https://www.researchgate.net/publication/303821785_Modelling_Symbolic_Music_Beyond_the_Piano_Roll}},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/E52KR9JM/303821785_Modelling_Symbolic_Music_Beyond_the_Piano_Roll.html:text/html},
  groups = {mmt-thesis}
}

@misc{_music_????,
  title = {From {{Music}} to {{Visuals}} - and {{Back}}. {{2D Fourier Transform}} Applied on {{Music Piano Roll Plots}}},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-02-06T21:58:58Z},
  urldate = {2017-02-06},
  howpublished = {\url{https://www.researchgate.net/publication/261684705_From_Music_to_Visuals_-_and_Back_2D_Fourier_Transform_applied_on_Music_Piano_Roll_Plots}},
  file = {From Music to Visuals - and Back.pdf:/Volumes/Transcend/zotero/storage/ZVD39X99/From Music to Visuals - and Back.pdf:application/pdf},
  groups = {mmt-thesis}
}

@misc{_p.i..n.o.:_????,
  title = {P.{{I}}.{{A}}.{{N}}.{{O}}.: {{Faster Piano Learning}} with {{Interactive Projection}}},
  shorttitle = {P.{{I}}.{{A}}.{{N}}.{{O}}.},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-02-06T22:01:56Z},
  urldate = {2017-02-06},
  howpublished = {\url{https://www.researchgate.net/publication/269873077_PIANO_Faster_Piano_Learning_with_Interactive_Projection}},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/V6F54556/269873077_PIANO_Faster_Piano_Learning_with_Interactive_Projection.html:text/html},
  groups = {mmt-thesis}
}

@misc{_end--end_????,
  title = {End-to-End Music Transcription Using a Neural Network},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-02-06T22:03:11Z},
  urldate = {2017-02-06},
  howpublished = {\url{https://www.researchgate.net/publication/310761497_End-to-end_music_transcription_using_a_neural_network}},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/8I88CCDF/310761497_End-to-end_music_transcription_using_a_neural_network.html:text/html},
  groups = {mmt-thesis}
}

@misc{_euterpea_????,
  title = {Euterpea | {{The Yale Haskell Group}}},
  timestamp = {2017-02-09T22:51:02Z},
  urldate = {2017-02-09},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/JCSG2JVC/euterpea.html:text/html},
  groups = {mmt-thesis}
}

@book{wigdor_brave_2011,
  address = {Burlington, Mass},
  title = {Brave {{NUI}} World: Designing Natural User Interfaces for Touch and Gesture},
  isbn = {978-0-12-382231-4},
  lccn = {QA76.9.U83 W537 2011},
  shorttitle = {Brave {{NUI}} World},
  timestamp = {2017-02-09T22:56:31Z},
  publisher = {{Morgan Kaufmann}},
  author = {Wigdor, Daniel and Wixon, Dennis},
  year = {2011},
  keywords = {Haptic devices,Human-computer interaction,NUI,User interfaces (Computer systems)}
}

@book{hudak_haskell_2000,
  address = {New York},
  title = {The {{Haskell}} School of Expression: Learning Functional Programming through Multimedia},
  isbn = {978-0-521-64338-2 978-0-521-64408-2},
  lccn = {QA76.62 .H83 2000},
  shorttitle = {The {{Haskell}} School of Expression},
  timestamp = {2017-02-09T23:01:41Z},
  publisher = {{Cambridge University Press}},
  author = {Hudak, Paul},
  year = {2000},
  keywords = {Functional programming (Computer science),Multimedia systems},
  groups = {mmt-thesis}
}

@article{hudak_haskell_2008,
  title = {The {{Haskell School}} of {{Music}}},
  timestamp = {2017-02-09T23:03:47Z},
  urldate = {2017-02-09},
  journal = {Yale University},
  author = {Hudak, Paul and {others}},
  year = {2008},
  file = {HSoM.pdf:/Volumes/Transcend/zotero/storage/NBUEESTP/HSoM.pdf:application/pdf},
  groups = {mmt-thesis}
}

@article{carpentier_predicting_????,
  title = {Predicting {{Timbre Features}} of {{Instrument Sound Combinations}}: {{Application}} to {{Automatic Orchestration}}},
  volume = {39},
  issn = {0929-8215},
  shorttitle = {Predicting {{Timbre Features}} of {{Instrument Sound Combinations}}},
  abstract = {Predicting Timbre Features of Instrument Sound Combinations: Application to Automatic Orchestration},
  timestamp = {2017-02-10T00:46:52Z},
  urldate = {2017-02-10},
  journal = {Journal of New Music Research},
  author = {Carpentier, Gr{\'e}goire and Tardieu, Damien and Harvey, Jonathan and Assayag, G{\'e}rard and Saint-James, Emmanuel},
  pages = {47--61},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/8VBN48VK/Predicting_Timbre_Features_of_Instrument_Sound_Combinations_Application_to_Automatic_Orchestrat.html:text/html},
  groups = {mmt-thesis}
}

@misc{_orchidee_????,
  title = {Orchidee [{{Music Representations Team}}]},
  timestamp = {2017-02-10T00:49:57Z},
  urldate = {2017-02-10},
  howpublished = {\url{http://repmus.ircam.fr/orchidee}},
  file = {orchidee [Music Representations Team]:/Volumes/Transcend/zotero/storage/9DSCKPEM/orchidee.html:text/html},
  groups = {mmt-thesis}
}

@misc{_process:_????,
  title = {Process: {{Aesthetic Engine}} 2},
  shorttitle = {Process},
  abstract = {On the web, data interpretation is defined by well-known rules. The semantics of data are defined by the system\&rsquo;s creators. Rendering is the end result of the two. But what if?In a web browser, clicking a link initiates a deluge of data, yet we as users remain mostly unaware of this process. Aesthetic Engine 2 is an application which encodes an alternative interpretation/visualization of web data, and the highly opinionated, artistic rendering of it.},
  timestamp = {2017-02-10T10:50:59Z},
  urldate = {2017-02-10},
  howpublished = {\url{http://brutalism.rs/post/process-aesthetic-engine-2/}},
  journal = {BRUTALISM},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/7ZUHZB7X/process-aesthetic-engine-2.html:text/html},
  groups = {mmt-thesis}
}

@article{boland_visualizing_2011,
  title = {{{VISUALIZING AND CONTROLLING SOUND WITH GRAPHICAL INTERFACES}}},
  abstract = {VISUALIZING AND CONTROLLING SOUND WITH GRAPHICAL INTERFACES},
  timestamp = {2017-02-10T14:14:12Z},
  urldate = {2017-02-10},
  journal = {Audio Engineering Society 41st Conference: Audio for Games (2011).},
  author = {Boland, Frank and Sullivan, Liam O.},
  year = {2011},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/525XW6QG/VISUALIZING_AND_CONTROLLING_SOUND_WITH_GRAPHICAL_INTERFACES.html:text/html},
  groups = {mmt-thesis}
}

@article{sullivan_it_2013,
  title = {It {{Looks}} as It {{Sounds}}: {{On}} the Use of {{Images}} as {{Controllers}} of {{Audiovisual Material}} in {{Graphical User Interfaces}}},
  shorttitle = {It {{Looks}} as It {{Sounds}}},
  abstract = {It Looks as it Sounds: On the use of Images as Controllers of Audiovisual Material in Graphical User Interfaces},
  timestamp = {2017-02-10T15:04:49Z},
  urldate = {2017-02-10},
  author = {Sullivan, Liam O.},
  year = {2013},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/F4VIEI8A/It_Looks_as_it_Sounds_On_the_use_of_Images_as_Controllers_of_Audiovisual_Material_in_Graphical_.html:text/html},
  groups = {mmt-thesis}
}

@misc{_highc_2017,
  title = {{{HighC}} - {{Draw}} Your {{Music}}},
  abstract = {HighC is a graphical music creation and composition software tool. Its goal is to make music composition as simple and direct as sketching.},
  timestamp = {2017-02-10T15:14:15Z},
  urldate = {2017-02-10},
  howpublished = {\url{http://highc.org}},
  journal = {HighC - Draw your Music},
  year = {2017},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/BT94D2B3/highc.org.html:text/html},
  groups = {mmt-thesis}
}

@article{chen_wetbrush:_2015,
  title = {Wetbrush: {{Gpu}}-Based 3d Painting Simulation at the Bristle Level},
  volume = {34},
  shorttitle = {Wetbrush},
  timestamp = {2017-02-10T15:33:39Z},
  number = {6},
  urldate = {2017-02-10},
  journal = {ACM Transactions on Graphics (TOG)},
  author = {Chen, Zhili and Kim, Byungmoon and Ito, Daichi and Wang, Huamin},
  year = {2015},
  pages = {200},
  file = {Chen-2015-WB.pdf:/Volumes/Transcend/zotero/storage/RZT5NZH8/Chen-2015-WB.pdf:application/pdf},
  groups = {mmt-thesis}
}

@misc{diverdi_brush_2013,
  title = {A {{Brush Stroke Synthesis Toolbox}}},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-02-10T15:38:42Z},
  urldate = {2017-02-10},
  howpublished = {\url{https://www.researchgate.net/publication/284569392_A_Brush_Stroke_Synthesis_Toolbox}},
  author = {Diverdi, Stephen},
  year = {2013},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/BITS3998/284569392_A_Brush_Stroke_Synthesis_Toolbox.html:text/html},
  groups = {mmt-thesis}
}

@article{sigursson_live_????,
  title = {Live {{Coding}} and {{Csound}}},
  doi = {10.5281/zenodo.50366},
  abstract = {In this paper I'm going to cover a way to design a live-coding front end for Csound. My programming language of choice is Clojure, which I've used to develop Panaeolus, a live-coding program built with CsoundAPI. The aim of Panaeolus is not only to bring Csound into the world of functional programming and lisp, but also to build an extendable musical system that can create complex musical pattern, with as short and descriptive code as possible. The origin of Panaeolus dates back to April 2015 when I was using Overtone (SupercolliderAPI for Clojure) for live-coding. Initially I just added few Csound instruments into my live-coding sets, but as my preference for the acoustical qualities of Csound are greater than those of Supercollider, I decided to leave the world of Supercollider and began to develop my own live-coding environment in July that same year. At the time of this writing, Panaeolus still needs better documentation, testing and stable release. It can be found under GNU license on http://github.com/hlolli/panaeolus. Even tough I will explain concepts in this paper that apply to Clojure, I will to point out that almost identical principles apply to other programming languages, even the Csound language itself. And at the time of this writing, a short article of live-coding in the Csound language with CsoundQt front-end is scheduled for Csound Journal spring issue of 2016.},
  timestamp = {2017-02-11T21:30:55Z},
  urldate = {2017-02-11},
  journal = {Zenodo},
  author = {Sigur{\dh}sson, Hl{\"o}{\dh}ver},
  file = {Sigurðsson_Live Coding and Csound.pdf:/Volumes/Transcend/zotero/storage/NW3AJSQC/Sigurðsson_Live Coding and Csound.pdf:application/pdf;Snapshot:/Volumes/Transcend/zotero/storage/B3RV52B5/50366.html:text/html},
  groups = {mmt-thesis}
}

@misc{_odesi_????,
  title = {Odesi 2.0},
  abstract = {Odesi is a digital download, so the link will arrive immediately. It comes with a 30-day money back guarantee because we love our customers and want to make sure you're always happy.Get your Odesi (Windows + Mac download) for just \$49 US:},
  timestamp = {2017-02-18T14:21:09Z},
  urldate = {2017-02-18},
  howpublished = {\url{http://welcome.odesi.com/yw}},
  journal = {Odesi 2.0},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/25PG4QG9/yw.html:text/html},
  groups = {mmt-thesis}
}

@misc{sonic_writing_sally_2016,
  title = {Sally {{Jane Norman}}: {{New Notations}} and {{Embodied Experience}}},
  shorttitle = {Sally {{Jane Norman}}},
  abstract = {Sally Jane Norman presents 'New Notations and Embodied Experience' at the New Notations Symposium held at IRCAM in Paris during September 2016.},
  timestamp = {2017-02-18T14:35:11Z},
  urldate = {2017-02-18},
  author = {{Sonic Writing}},
  year = {2016},
  groups = {mmt-thesis}
}

@misc{_digital_????,
  title = {Digital {{Brushes}}},
  abstract = {Maintainer: Eyecager/Amber Blade Jones Email me about broken links here: amberbladejones@gmail.com},
  timestamp = {2017-02-19T14:14:36Z},
  urldate = {2017-02-19},
  howpublished = {\url{http://digitalbrushes.tumblr.com/?og=1}},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/P8WIF2JP/digitalbrushes.tumblr.com.html:text/html},
  groups = {mmt-thesis}
}

@misc{_why_????,
  title = {Why Expression},
  timestamp = {2017-02-19T14:18:57Z},
  urldate = {2017-02-19},
  howpublished = {\url{http://www.rogerlinndesign.com/why-expression.html}},
  file = {Why expression:/Volumes/Transcend/zotero/storage/K8IKZPPF/why-expression.html:text/html},
  groups = {mmt-thesis}
}

@misc{_music_????-1,
  title = {The {{Music Room}}: {{Unique Instruments}}, {{Inspiring Spaces}} in {{VR}}},
  timestamp = {2017-02-19T14:24:23Z},
  urldate = {2017-02-19},
  howpublished = {\url{http://musicroomvr.com/}},
  file = {The Music Room\: Unique Instruments, Inspiring Spaces in VR:/Volumes/Transcend/zotero/storage/JATGHP97/musicroomvr.com.html:text/html},
  groups = {mmt-thesis}
}

@misc{_making_2016,
  title = {Making {{Music In VR}}: '{{The Music Room}},' {{Hands On}}},
  shorttitle = {Making {{Music In VR}}},
  abstract = {To fully understand what a laser harp is (and how it works), we spent some time with the SteamVR version of "The Music Room" to see just what we could do with a virtual MIDI studio at our disposal.},
  timestamp = {2017-02-19T14:34:38Z},
  urldate = {2017-02-19},
  howpublished = {\url{http://www.tomshardware.com/news/music-room-chroma-coda-vr,32783.html}},
  journal = {Tom's Hardware},
  month = sep,
  year = {2016},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/RGJI6M35/music-room-chroma-coda-vr,32783.html:text/html},
  groups = {mmt-thesis}
}

@misc{_draw_2016,
  title = {Draw {{Collaboratively In VR}}: {{Google Experimenting With Multiplayer Tilt Brush}}},
  shorttitle = {Draw {{Collaboratively In VR}}},
  abstract = {Google is always experimenting with new ideas for Tilt Brush. Multiplayer is one of the latest, and more promising, innovations. It just may see a public release.},
  timestamp = {2017-02-19T14:36:56Z},
  urldate = {2017-02-19},
  howpublished = {\url{http://www.tomshardware.com/news/google-tilt-brush-vr-game,32788.html}},
  journal = {Tom's Hardware},
  month = sep,
  year = {2016},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/FKZTFAB2/google-tilt-brush-vr-game,32788.html:text/html},
  groups = {mmt-thesis}
}

@misc{google_vr_tilt_????,
  title = {Tilt {{Brush}}: {{Jolly Bones}}},
  shorttitle = {Tilt {{Brush}}},
  abstract = {Google has been working closely with more than 60 artists to help them explore their style in virtual reality as part of the Tilt Brush Artist in Residence program (AiR). Coming from a wide range of disciplines, these graffiti artists, painters, illustrators, graphic designers, dancers, concept artists, creative technologists and cartoonists have all brought their passion and talent to create some amazing art with Tilt Brush.

Learn more and view their work at www.tiltbrush.com/air},
  timestamp = {2017-02-19T14:40:49Z},
  urldate = {2017-02-19},
  author = {{Google VR}},
  keywords = {htc vive,pirate,tilt brush,vr},
  groups = {mmt-thesis}
}

@misc{_image--image_????,
  title = {Image-to-{{Image Demo}} - {{Affine Layer}}},
  timestamp = {2017-02-23T14:28:11Z},
  urldate = {2017-02-23},
  howpublished = {\url{http://affinelayer.com/pixsrv/}},
  file = {Image-to-Image Demo - Affine Layer:/Volumes/Transcend/zotero/storage/XXBZVEMZ/pixsrv.html:text/html},
  groups = {mmt-thesis}
}

@misc{_beholder.jpg_????,
  title = {Beholder.Jpg (691\texttimes{}398)},
  timestamp = {2017-02-23T14:32:35Z},
  urldate = {2017-02-23},
  howpublished = {\url{http://affinelayer.com/pixsrv/beholder.jpg}},
  file = {beholder.jpg (691×398):/Volumes/Transcend/zotero/storage/BRTFMDIC/beholder.html:text/html},
  groups = {mmt-thesis}
}

@misc{_r-e-s-t_????,
  title = {R-{{E}}-{{S}}-{{T}} and {{Composition}}: {{Silence}}, {{Breath}} and Aah ? [{{Gap}}] {{Musical Rest}}},
  shorttitle = {R-{{E}}-{{S}}-{{T}} and {{Composition}}},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-02-23T15:16:27Z},
  urldate = {2017-02-23},
  howpublished = {\url{https://www.researchgate.net/publication/308707387_R-E-S-T_and_Composition_Silence_Breath_and_aah_Gap_Musical_Rest}},
  file = {R-E-S-T and Composition.pdf:/Volumes/Transcend/zotero/storage/6W4Z82WX/R-E-S-T and Composition.pdf:application/pdf},
  groups = {mmt-thesis}
}

@misc{popova_100_2012,
  title = {100 {{Diagrams That Changed}} the {{World}}},
  abstract = {A visual history of human sensemaking, from cave paintings to the world wide web.},
  timestamp = {2017-02-28T11:12:11Z},
  urldate = {2017-02-28},
  journal = {Brain Pickings},
  author = {Popova, Maria},
  year = {2012-12-21T13:00:03+00:00},
  annote = {But most noteworthy of all is the way in which these diagrams bespeak an essential part of culture \textemdash{} the awareness that~everything builds on what came before, that~creativity is combinatorial, and that the most radical innovations harness~the cross-pollination of disciplines.~},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/IFPHAD68/100-diagrams-that-changed-the-world.html:text/html},
  groups = {mmt-thesis}
}

@misc{_edward_????,
  title = {Edward {{Tufte}} Forum: {{Display}} of Musical Structure},
  timestamp = {2017-02-28T11:20:29Z},
  urldate = {2017-02-28},
  howpublished = {\url{https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000MB}},
  annote = {On a related subject (music notation - old and new), there was an interesting interview with contemporary music composer Karlheinz Stockhausen in Le Monde (French newspaper of record) on 2005/08/08. Stockhausen often invented new notations to adequately represent his music, and since 1970 directly manages publishing of his works.
The following excerpt reminded me of ET writings:
~
"Votre gout pour le dessin transparait {\'e}galement dans vos partitions, r{\'e}alis{\'e}es avec minutie jusque dans l'utilisation des couleurs. Est- ce la un plaisir d'esthete ?
Absolument pas. D{\`e}s mes d{\'e}buts de compositeur, j'ai r{\'e}alis{\'e} que la pr{\'e}cision du dessin {\'e}tait essentielle pour une ex{\'e}cution sans faute de la musique. Je me suis attel{\'e} a cette tache pour chacune des 330 oeuvres cr{\'e}{\'e}es a ce jour. Que restera-t-il de moi a la fin de cette vie ? Avant tout des partitions. Elles doivent donc etre sur le plan graphique aussi limpides et belles que possible.
[...]~Une grande part de vos activites consiste a dessiner les partitions et a repeter les oeuvres, n'est-ce pas du temps perdu pour la composition proprement dite ?
Non, car ca fait partie de la composition. Pour moi, la composition n'existerait pas sans la realisation des partitions et le travail de repetition. "

My rough translation:
~
"~Your taste for drawing is also apparent in your scores, with meticulous attention to detail, including use of color. Is this aesthete's pleasure ?
Absolutely not. From my beginnings as a composer, I realized that drawing precision was essential for flawless music performance. I committed myself to the task for each of my 330 works to date. What will remain of me ? First and foremost scores. Thus, they must be on the graphic level as limpid and beautiful as possible.
[...] A major part of your activities is about drawing scores and rehearsing. Isn't that lost time for actual composition work ?
No, as it is part of composition work. For me, composition would not exist without score drawing and rehearsing. "

Stockhausen website has a few examples of sheet music:~http:// www.stockhausen.org/stopstart\_page1.html~http:// www.stockhausen.org/stopstart\_intro.html
I think there's another example in~The Visual Display of Quantitative Information.
-- Olivier Gutknecht (email)},
  file = {Edward Tufte forum\: Display of musical structure:/Volumes/Transcend/zotero/storage/5MTHWT3H/q-and-a-fetch-msg.html:text/html},
  groups = {mmt-thesis}
}

@misc{_macroscope_????,
  title = {Macroscope {{Manifesto}} 02-27-02},
  timestamp = {2017-02-28T11:30:01Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://radio-weblogs.com/0104369/stories/2002/04/09/macroscope022702.htm\#_edn9}},
  file = {Macroscope Manifesto 02-27-02:/Volumes/Transcend/zotero/storage/N4P7NIHV/macroscope022702.html:text/html},
  groups = {mmt-thesis}
}

@misc{_visual_????,
  title = {Visual Displays},
  abstract = {Music score with dance notation},
  timestamp = {2017-02-28T11:35:03Z},
  urldate = {2017-02-28},
  howpublished = {\url{https://www.pinterest.com/pin/104356916335417618/}},
  journal = {Pinterest},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/X6BTHTQ4/104356916335417618.html:text/html},
  groups = {mmt-thesis}
}

@misc{_graphic_2013,
  title = {Graphic Music Scores - in Pictures},
  abstract = {How do you play a picture? Composers and artists from John Cage to Brian Eno have experimented with notation to create extraordinary visual scores that rival the best contemporary art. Here Notation 21's Theresa Sauer introduces a selection of her favourites.},
  timestamp = {2017-02-28T11:36:53Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://www.theguardian.com/music/gallery/2013/oct/04/graphic-music-scores-in-pictures}},
  journal = {the Guardian},
  year = {2013-10-04T12:46:00.000Z},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/DJARBDHG/graphic-music-scores-in-pictures.html:text/html},
  groups = {mmt-thesis}
}

@misc{_edward_????-1,
  title = {Edward {{Tufte}} Forum: {{Music Animation Machine}}},
  timestamp = {2017-02-28T11:39:39Z},
  urldate = {2017-02-28},
  howpublished = {\url{https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=00005y}},
  file = {Edward Tufte forum\: Music Animation Machine:/Volumes/Transcend/zotero/storage/SXQGK2WU/q-and-a-fetch-msg.html:text/html},
  groups = {mmt-thesis}
}

@misc{malinowski_music_2017,
  title = {Music {{Animation Machine}}},
  timestamp = {2017-08-04T09:18:37Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://www.musanim.com/}},
  author = {Malinowski, Stephen},
  year = {2017},
  keywords = {music viz},
  file = {Music Animation Machine:/Volumes/Transcend/zotero/storage/R3U49ZE2/www.musanim.com.html:text/html},
  groups = {mmt-thesis}
}

@misc{_conductor_????,
  title = {Conductor {{Program}} (Computer-Mediated Performance)},
  timestamp = {2017-02-28T11:42:22Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://www.musanim.com/tapper/}},
  file = {Conductor Program (computer-mediated performance):/Volumes/Transcend/zotero/storage/7V732SMG/tapper.html:text/html},
  groups = {mmt-thesis}
}

@misc{ethan_visualizing_2011,
  title = {Visualizing Music},
  abstract = {Update: check out my masters thesis, a radial drum machine. Specifically, see the section on visualizing rhythm. See also a more scholarly review of the literature on visualization and music educat\ldots{}},
  timestamp = {2017-02-28T11:49:25Z},
  urldate = {2017-02-28},
  journal = {The Ethan Hein Blog},
  author = {{Ethan}},
  year = {2011-10-11T20:31:23+00:00},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/DGD4R9VZ/visualizing-music.html:text/html},
  groups = {mmt-thesis}
}

@misc{ethan_affordances_2017,
  title = {Affordances and {{Constraints}}},
  abstract = {Note-taking for User Experience Design with June Ahn Don Norman discusses affordances and constraints in~The Design of Everyday Things, Chapter Four: Knowing What To Do. User experience design is e\ldots{}},
  timestamp = {2017-02-28T12:21:40Z},
  urldate = {2017-02-28},
  journal = {The Ethan Hein Blog},
  author = {{Ethan}},
  year = {2017-01-27T16:30:18+00:00},
  keywords = {Design},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/FHF2XGWA/affordances-and-constraints.html:text/html}
}

@misc{_walrus_????,
  title = {Walrus - {{Graph Visualization Tool}}},
  timestamp = {2017-02-28T12:26:24Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://www.caida.org/tools/visualization/walrus/}},
  file = {Walrus - Graph Visualization Tool:/Volumes/Transcend/zotero/storage/C2KJ7W66/walrus.html:text/html},
  groups = {mmt-thesis}
}

@misc{_noneuclid_????,
  title = {{{NonEuclid}} - {{Hyperbolic Geometry Article}} and {{Javascript Software}}},
  timestamp = {2017-02-28T12:31:49Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://cs.unm.edu/~joel/NonEuclid/}},
  file = {NonEuclid - Hyperbolic Geometry Article and Javascript Software:/Volumes/Transcend/zotero/storage/FUFA4QVN/NonEuclid.html:text/html},
  groups = {mmt-thesis}
}

@misc{_cubic_????,
  title = {Cubic {{Limit}} $\leftarrow$ {{Stream}} $\leftarrow$ {{MuDA}} $\carriagereturn$},
  abstract = {Cubic Limit by digital arts pioneer Manfred Mohr.},
  timestamp = {2017-02-28T14:46:48Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://muda.co/stream/cubic.php}},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/WIJW5WNS/cubic.html:text/html},
  groups = {mmt-thesis}
}

@misc{_don_????,
  title = {Don {{Knuth}}'s {{Home Page}}},
  timestamp = {2017-02-28T14:56:32Z},
  urldate = {2017-02-28},
  howpublished = {\url{http://www-cs-faculty.stanford.edu/~uno/}},
  file = {Don Knuth's Home Page:/Volumes/Transcend/zotero/storage/V23768Q8/~uno.html:text/html},
  groups = {mmt-thesis}
}

@misc{_harmony_????,
  title = {Harmony {{Explained}}: {{Progress Towards A Scientific Theory}} of {{Music}}},
  timestamp = {2017-03-01T11:09:22Z},
  urldate = {2017-03-01},
  howpublished = {\url{https://arxiv.org/html/1202.4212v1}},
  file = {Harmony Explained\: Progress Towards A Scientific Theory of Music:/Volumes/Transcend/zotero/storage/F3APNUQ3/1202.html:text/html},
  groups = {mmt-thesis}
}

@misc{_velato:_2009,
  title = {Velato: {{What}} If {{Musical Notes Had Their Own Programming Language}}?},
  shorttitle = {Velato},
  abstract = {Photo (CC) Quinn Dombrowski. Composing music is not unlike programming \textendash{} and either, at their best, can be expressive. In the early days of IT (before ``IT'' was even a term), many computer programmers came from a musical background. (And even early in the computer age, there was more call for software than symphonies \textendash{} and more pay.) But what if you could program music easily, using musical syntax in a programming language? That's the question asked by languages like Velato. The commands actually aren't as esoteric as you might expect; they include references to standard pitch and commands like ...},
  timestamp = {2017-03-01T17:16:53Z},
  urldate = {2017-03-01},
  journal = {CDM Create Digital Music},
  year = {2009-01-29T11:23:18+01:00},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/RXPK4J24/verlato-what-if-musical-notes-had-their-own-programming-language.html:text/html},
  groups = {mmt-thesis}
}

@misc{_velato_????,
  title = {Velato},
  timestamp = {2017-03-01T17:17:46Z},
  urldate = {2017-03-01},
  howpublished = {\url{http://velato.net/}},
  file = {Velato:/Volumes/Transcend/zotero/storage/66KQ2ZUU/velato.net.html:text/html},
  groups = {mmt-thesis}
}

@misc{_daphne_????,
  title = {Daphne {{Oram}} Documentary - {{Wee Have Also Sound}}-{{Houses}} - {{YouTube}}},
  abstract = {Enjoy the videos and music you love, upload original content and share it all with friends, family and the world on YouTube.},
  timestamp = {2017-03-05T18:13:12Z},
  urldate = {2017-03-05},
  howpublished = {\url{https://www.youtube.com/}},
  annote = {https://youtu.be/NNaqvAH7R34?t=26m7s
~
Much more composed and knitted together than the harsher European composers. Much more delicate and flowing than the blocks of sound of the European style.},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/R3QQZQ9U/watch.html:text/html},
  groups = {mmt-thesis}
}

@misc{_generative_2016,
  title = {Generative Theory of Tonal Music},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {A generative theory of tonal music (GTTM) is a theory of music conceived by American composer and music theorist Fred Lerdahl and American linguist Ray Jackendoff and presented in the 1983 book of the same title. It constitutes a "formal description of the musical intuitions of a listener who is experienced in a musical idiom" with the aim of illuminating the unique human capacity for musical understanding.
The collaboration between Lerdahl and Jackendoff was inspired by Leonard Bernstein's 1973 Charles Eliot Norton Lectures at Harvard University, wherein he called for researchers to uncover a musical grammar that could explain the human musical mind in a scientific manner comparable to Noam Chomsky's revolutionary transformational or generative grammar.
Unlike the major methodologies of music analysis that preceded it, GTTM construes the mental procedures under which the listener constructs an unconscious understanding of music, and uses these tools to illuminate the structure of individual compositions. The theory has been influential, spurring further work by its authors and other researchers in the fields of music theory, music cognition and cognitive musicology.},
  language = {en},
  timestamp = {2017-03-11T14:43:49Z},
  urldate = {2017-03-11},
  journal = {Wikipedia},
  month = jul,
  year = {2016},
  note = {Page Version ID: 732219979},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/65USFBMV/index.html:text/html},
  groups = {mmt-thesis}
}

@misc{_music_????-3,
  title = {Music {{Notation Style Guide}}: {{Composition}}: {{Departments}}, {{Offices}} and {{Services}}: {{Jacobs School}} of {{Music}}: {{Indiana University Bloomington}}},
  timestamp = {2017-03-11T15:07:56Z},
  urldate = {2017-03-11},
  howpublished = {\url{http://www.music.indiana.edu/departments/academic/composition/style-guide/}},
  file = {Music Notation Style Guide\: Composition\: Departments, Offices and Services\: Jacobs School of Music\: Indiana University Bloomington:/Volumes/Transcend/zotero/storage/UWWUQNJM/style-guide.html:text/html},
  groups = {mmt-thesis}
}

@book{_visual_????-1,
  title = {Visual {{Language Theory}} | {{Kim Marriott}} | {{Springer}}},
  abstract = {Kim Marriott Bernd Meyer Communication is one of the hallmarks of humans. When we think of hu$\-$ man communication, most people first think of spoken and...},
  timestamp = {2017-03-11T15:36:23Z},
  urldate = {2017-03-11},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/XXIMDPJV/9780387983677.html:text/html},
  groups = {mmt-thesis}
}

@misc{_rastrum_2016,
  title = {Rastrum},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {A rastrum (or raster) is a five-pointed writing implement used in music manuscripts to draw parallel staff lines when drawn horizontally across a blank piece of sheet music. The word "raster" is derived from the Latin for "rake". Rastra were used to draw lines on paper that had not been pre-ruled, and were widely used in Europe until printed staff paper became cheap and common in the nineteenth century. Some rastra are able to draw more than one staff at a time. Rastrology, the study of the use of the rastrum, is a branch of music manuscript studies that uses information about the rastrum to help find the date and provenance of musical materials.},
  language = {en},
  timestamp = {2017-03-11T15:48:28Z},
  urldate = {2017-03-11},
  journal = {Wikipedia},
  month = oct,
  year = {2016},
  note = {Page Version ID: 747091708},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/8JQZSBNA/index.html:text/html},
  groups = {mmt-thesis}
}

@article{_implementing_2007,
  title = {Implementing Synthesis Control Using Timbral Adjectives},
  volume = {121},
  issn = {0001-4966},
  doi = {10.1121/1.4782089},
  timestamp = {2017-03-13T23:32:36Z},
  number = {5},
  urldate = {2017-03-13},
  journal = {The Journal of the Acoustical Society of America},
  month = may,
  year = {2007},
  pages = {3119--3120},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/UKTDHIS2/1.html:text/html},
  groups = {mmt-thesis}
}

@article{elliott_acoustic_2013,
  title = {Acoustic Structure of the Five Perceptual Dimensions of Timbre in Orchestral Instrument Tones},
  volume = {133},
  issn = {00014966},
  doi = {10.1121/1.4770244},
  abstract = {Attempts to relate the perceptual dimensions of timbre to quantitative acoustical dimensions have been tenuous, leading to claims that timbre is an emergent property, if measurable at all. Here, a three-pronged analysis shows that the timbre space of sustained instrument tones occupies 5 dimensions and that a specific combination of acoustic properties uniquely determines gestalt perception of timbre. Firstly, multidimensional scaling (MDS) of dissimilarity judgments generated a perceptual timbre space in which 5 dimensions were cross-validated and selected by traditional model comparisons. Secondly, subjects rated tones on semantic scales. A discriminant function analysis (DFA) accounting for variance of these semantic ratings across instruments and between subjects also yielded 5 significant dimensions with similar stimulus ordination. The dimensions of timbre space were then interpreted semantically by rotational and reflectional projection of the MDS solution into two DFA dimensions. Thirdly, to relate this final space to acoustical structure, the perceptual MDS coordinates of each sound were regressed with its joint spectrotemporal modulation power spectrum. Sound structures correlated significantly with distances in perceptual timbre space. Contrary to previous studies, most perceptual timbre dimensions are not the result of purely temporal or spectral features but instead depend on signature spectrotemporal patterns.},
  timestamp = {2017-03-13T23:33:45Z},
  number = {1},
  urldate = {2017-03-13},
  journal = {Journal of the Acoustical Society of America},
  author = {Elliott, Taffeta M. and Hamilton, Liberty S. and Theunissen, Fr{\'e}d{\'e}ric E.},
  month = jan,
  year = {2013},
  keywords = {GESTALT psychology,MUSIC -- Acoustics \& physics,MUSICAL groups,ORCHESTRA,TONE color (Music theory)},
  pages = {389--404},
  file = {Elliott et al_2013_Acoustic structure of the five perceptual dimensions of timbre in orchestral.pdf:/Volumes/Transcend/zotero/storage/7MGABUZW/Elliott et al_2013_Acoustic structure of the five perceptual dimensions of timbre in orchestral.pdf:application/pdf},
  groups = {mmt-thesis}
}

@misc{_image_????,
  title = {Image Processing - {{2D Shape}} Recognition Algorithm - Looking for Guidance - {{Stack Overflow}}},
  timestamp = {2017-03-14T11:49:03Z},
  urldate = {2017-03-14},
  howpublished = {\url{http://stackoverflow.com/questions/25148136/2d-shape-recognition-algorithm-looking-for-guidance}},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/J25E82TC/2d-shape-recognition-algorithm-looking-for-guidance.html:text/html},
  groups = {mmt-thesis}
}

@misc{_supervised_????,
  title = {Supervised {{Learning Workflow}} and {{Algorithms}} - {{MATLAB}} \& {{Simulink}} - {{MathWorks United Kingdom}}},
  timestamp = {2017-03-14T11:52:32Z},
  urldate = {2017-03-14},
  howpublished = {\url{http://uk.mathworks.com/help/stats/supervised-learning-machine-learning-workflow-and-algorithms.html?requestedDomain=nl.mathworks.com}},
  file = {Supervised Learning Workflow and Algorithms - MATLAB & Simulink - MathWorks United Kingdom:/Volumes/Transcend/zotero/storage/INE86A34/supervised-learning-machine-learning-workflow-and-algorithms.html:text/html},
  groups = {mmt-thesis}
}

@misc{_adaptive_????,
  title = {The {{Adaptive Hybrid Cursor}}: {{A Pressure}}-{{Based Target Selection Technique}} for {{Pen}}-{{Based User Interfaces}}},
  shorttitle = {The {{Adaptive Hybrid Cursor}}},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-03-15T11:42:41Z},
  urldate = {2017-03-15},
  howpublished = {\url{https://www.researchgate.net/publication/221054333_The_Adaptive_Hybrid_Cursor_A_Pressure-Based_Target_Selection_Technique_for_Pen-Based_User_Interfaces}},
  journal = {ResearchGate},
  keywords = {Digital pen},
  file = {The_Adaptive_Hybrid_Cursor_A_Pressure-Based_Target (1).pdf:/Volumes/Transcend/zotero/storage/68EIV59G/The_Adaptive_Hybrid_Cursor_A_Pressure-Based_Target (1).pdf:application/pdf}
}

@misc{markou_black_????,
  title = {The {{Black Magic}} of {{Deep Learning}} - {{Tips}} and {{Tricks}} for the Practitioner},
  abstract = {I've been using Deep Learning and Deep Belief Networks since 2013.  I was involved in a green field project and I was in charge of deciding...},
  timestamp = {2017-03-18T14:02:07Z},
  urldate = {2017-03-18},
  author = {Markou, Nikolas},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/PBXPBSM7/the-black-magic-of-deep-learning-tips.html:text/html},
  groups = {mmt-thesis}
}

@inproceedings{camurri_analysis_2003,
  title = {Analysis of {{Expressive Gesture}}: {{The EyesWeb Expressive Gesture Processing Library}}},
  shorttitle = {Analysis of {{Expressive Gesture}}},
  doi = {10.1007/978-3-540-24598-8_42},
  abstract = {This paper presents some results of a research work concerning algorithms and computational models for real-time analysis of expressive gesture in full-body human movement. As a main concrete result of our research work, we present a collection of algorithms and related software modules for the EyesWeb open architecture (freely available from www.eyesweb.org). These software modules, collected in the EyesWeb Expressive Gesture Processing Library, have been used in real scenarios and applications, mainly in the fields of performing arts, therapy and rehabilitation, museum interactive installations, and other immersive augmented reality and cooperative virtual environment applications. The work has been carried out at DIST \textendash{} InfoMus Lab in the framework of the EU IST Project MEGA (Multisensory Expressive Gesture Applications, www.megaproject.org).},
  language = {en},
  timestamp = {2017-03-27T13:50:08Z},
  urldate = {2017-03-27},
  booktitle = {Gesture-{{Based Communication}} in {{Human}}-{{Computer Interaction}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Camurri, Antonio and Mazzarino, Barbara and Volpe, Gualtiero},
  month = apr,
  year = {2003},
  pages = {460--467},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/RVZCUIMX/978-3-540-24598-8_42.html:text/html},
  groups = {mmt-thesis}
}

@article{agon_omchroma:_2011,
  title = {{{OMChroma}}: {{Compositional Control}} of {{Sound Synthesis}}},
  shorttitle = {{{OMChroma}}},
  timestamp = {2017-04-14T19:36:02Z},
  number = {2},
  urldate = {2017-04-14},
  journal = {Computer Music Journal},
  author = {Agon, Carlos and Bresson, Jean and Stroppa, Marco},
  year = {2011},
  keywords = {Computer composition,OMChroma (Computer file)},
  pages = {67},
  file = {Agon et al_2011_OMChroma.pdf:/Volumes/Transcend/zotero/storage/TIHJFVUU/Agon et al_2011_OMChroma.pdf:application/pdf},
  groups = {mmt-thesis}
}

@misc{_gesture_????,
  title = {A {{Gesture}} Follower for Performing Arts},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  timestamp = {2017-04-16T10:47:26Z},
  urldate = {2017-04-16},
  howpublished = {\url{https://www.researchgate.net/publication/255670085_A_Gesture_follower_for_performing_arts}},
  journal = {ResearchGate},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/GIWD6IJ9/255670085_A_Gesture_follower_for_performing_arts.html:text/html},
  groups = {mmt-thesis}
}

@inproceedings{maccallum_dynamic_2015,
  title = {Dynamic {{Message}}-{{Oriented Middleware}} with {{Open Sound Control}} and {{Odot}}},
  timestamp = {2017-04-21T08:49:35Z},
  urldate = {2017-04-21},
  booktitle = {International {{Computer Music Conference}}},
  author = {MacCallum, John and Gottfried, Rama and Rostovtsev, Ilya and Bresson, Jean and Freed, Adrian},
  year = {2015},
  file = {dynamic-message-oriented-middleware-with-open-sound-control.pdf:/Volumes/Transcend/zotero/storage/9KGG84N7/dynamic-message-oriented-middleware-with-open-sound-control.pdf:application/pdf},
  groups = {mmt-thesis,pds-assign2}
}

@article{caramiaux_adaptive_2015,
  title = {Adaptive Gesture Recognition with Variation Estimation for Interactive Systems},
  volume = {4},
  timestamp = {2017-04-21T08:51:34Z},
  number = {4},
  urldate = {2017-04-21},
  journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},
  author = {Caramiaux, Baptiste and Montecchio, Nicola and Tanaka, Atau and Bevilacqua, Fr{\'e}d{\'e}ric},
  year = {2015},
  pages = {18},
  file = {gvf_tiis_si.pdf:/Volumes/Transcend/zotero/storage/UUVS3VCX/gvf_tiis_si.pdf:application/pdf}
}

@article{duignan_computer_2008,
  title = {Computer {{Mediated Music Production}}: A {{Study}} of {{Abstraction}} and {{Activity}}},
  shorttitle = {Computer {{Mediated Music Production}}},
  abstract = {Human Computer Interaction research has a unique challenge in understanding the activity systems of creative professionals, and designing the user-interfaces to support their work. In these activities, the user is involved in the process of building and editing complex digital artefacts through a process of continued refinement, as is seen in computer aided architecture, design, animation, movie-making, 3D modelling, interactive media (such as shockwave-flash), as well as audio and music production. This thesis examines the ways in which abstraction mechanisms present in music production
systems interplay with producers' activity through a collective case study of seventeen professional producers. From the basis of detailed observations
and interviews we examine common abstractions provided by the ubiquitous multitrack-mixing metaphor and present design implications for future systems.},
  language = {en\_NZ},
  timestamp = {2017-04-22T17:34:03Z},
  urldate = {2017-04-22},
  author = {Duignan, Matthew},
  year = {2008},
  keywords = {DAW},
  file = {Duignan_2008_Computer Mediated Music Production.pdf:/Volumes/Transcend/zotero/storage/JQXGF5TJ/Duignan_2008_Computer Mediated Music Production.pdf:application/pdf;Snapshot:/Volumes/Transcend/zotero/storage/AUA9UQCQ/590.html:text/html}
}

@misc{bell_journal_2015,
  title = {Journal on the {{Art}} of {{Record Production}} \guillemotright{} {{Beyond Skeuomorphism}}: {{The Evolution}} of {{Music Production Software User Interface Metaphors}}},
  timestamp = {2017-05-01T15:33:33Z},
  urldate = {2017-04-23},
  howpublished = {\url{http://arpjournal.com/beyond-skeuomorphism-the-evolution-of-music-production-software-user-interface-metaphors-2/}},
  author = {Bell, Adam and Hein, Ethan and Ratcliffe, Jarrod},
  year = {2015},
  keywords = {DAW},
  file = {Journal on the Art of Record Production » Beyond Skeuomorphism\: The Evolution of Music Production Software User Interface Metaphors:/Volumes/Transcend/zotero/storage/HNK8ZD7B/beyond-skeuomorphism-the-evolution-of-music-production-software-user-interface-metaphors-2.html:text/html}
}

@misc{hein_designing_2013,
  title = {Designing the {{Drum Loop}} - {{A}} Constructivist {{iOS}} Rhythm Tutorial System for Beginner ({{Thesis}})},
  timestamp = {2017-04-23T11:08:22Z},
  author = {Hein, Ethan},
  year = {2013},
  keywords = {DAW,Design},
  file = {ethan hein thesis.pdf:/Volumes/Transcend/zotero/storage/CNI6485R/ethan hein thesis.pdf:application/pdf}
}

@misc{popova_10_2012,
  title = {10 {{Rules}} for {{Students}}, {{Teachers}}, and {{Life}} by {{John Cage}} and {{Sister Corita Kent}}},
  abstract = {``Nothing is a mistake. There's no win and no fail, there's only make.''},
  timestamp = {2017-05-02T12:24:41Z},
  urldate = {2017-05-02},
  journal = {Brain Pickings},
  author = {Popova, Maria},
  year = {2012},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/KMZ6BMIC/10-rules-for-students-and-teachers-john-cage-corita-kent.html:text/html}
}

@misc{_aphex_2017,
  title = {Aphex {{Twin Speaks To Ex}}. {{Korg Engineer Tatsuya Takahashi}} | {{WARP}} | {{Item}}},
  timestamp = {2017-07-25T12:36:23Z},
  urldate = {2017-07-25},
  howpublished = {\url{http://item.warp.net/interview/aphex-twin-speaks-to-tatsuya-takahashi/}},
  journal = {warp},
  year = {2017},
  file = {Aphex Twin Speaks To Ex. Korg Engineer Tatsuya Takahashi | WARP | Item:/Volumes/Transcend/zotero/storage/K5ZDZD35/aphex-twin-speaks-to-tatsuya-takahashi.html:text/html},
  groups = {mmt-thesis}
}

@article{dannenberg_resource-instance_1991,
  title = {The Resource-Instance Model of Music Representation},
  timestamp = {2017-07-28T15:19:56Z},
  urldate = {2017-07-28},
  journal = {Computer Science Department},
  author = {Dannenberg, Roger B. and Rubine, Dean and Neuendorffer, Tom},
  year = {1991},
  pages = {482},
  file = {viewcontent.pdf:/Volumes/Transcend/zotero/storage/PU8QT2HS/viewcontent.pdf:application/pdf}
}

@inproceedings{mann_interactive_2015,
  title = {Interactive Music with Tone. Js},
  timestamp = {2017-07-28T17:58:56Z},
  urldate = {2017-07-28},
  booktitle = {Proceedings of the 1st Annual {{Web Audio Conference}}},
  author = {Mann, Yotam},
  year = {2015},
  file = {wac15_submission_40.pdf:/Volumes/Transcend/zotero/storage/KHA6EDQB/wac15_submission_40.pdf:application/pdf},
  groups = {mmt-thesis}
}

@article{vanhatalo_online_2011,
  title = {Online {{Sketch Recognition}}: {{Geometric Shapes}}},
  shorttitle = {Online {{Sketch Recognition}}},
  timestamp = {2017-08-03T22:05:26Z},
  urldate = {2017-08-03},
  author = {Vanhatalo, Lauri and {others}},
  year = {2011},
  file = {urn100500.pdf:/Volumes/Transcend/zotero/storage/52SJRSRN/urn100500.pdf:application/pdf},
  groups = {mmt-thesis}
}

@inproceedings{orlarey_algebraic_2002,
  title = {An Algebraic Approach to Block Diagram Constructions},
  timestamp = {2017-08-03T22:14:08Z},
  urldate = {2017-08-03},
  booktitle = {Proc. {{Journ{\'e}es}} d'{{Informatique Musicale}}},
  author = {Orlarey, Yann and Fober, Dominique and Letz, St{\'e}phane},
  year = {2002},
  file = {L18_Orlarey.pdf:/Volumes/Transcend/zotero/storage/6XBV7KR8/L18_Orlarey.pdf:application/pdf},
  groups = {mmt-thesis}
}

@article{fornes_cvc-muscima:_2012,
  title = {{{CVC}}-{{MUSCIMA}}: A Ground Truth of Handwritten Music Score Images for Writer Identification and Staff Removal},
  volume = {15},
  issn = {1433-2833, 1433-2825},
  shorttitle = {{{CVC}}-{{MUSCIMA}}},
  doi = {10.1007/s10032-011-0168-2},
  language = {en},
  timestamp = {2017-08-03T22:18:08Z},
  number = {3},
  journal = {International Journal on Document Analysis and Recognition (IJDAR)},
  author = {Forn{\'e}s, Alicia and Dutta, Anjan and Gordo, Albert and Llad{\'o}s, Josep},
  month = sep,
  year = {2012},
  pages = {243--251},
  groups = {mmt-thesis}
}

@misc{lauke_small_2017,
  title = {A Small Collection of Simple Touch/Pointer Tests and Demos},
  copyright = {MIT},
  timestamp = {2017-08-03T22:19:59Z},
  author = {Lauke, Patrick H.},
  month = jul,
  year = {2017},
  file = {Snapshot:/Volumes/Transcend/zotero/storage/D7EPM2PJ/touch.html:text/html},
  groups = {mmt-thesis}
}

@misc{_production_????,
  title = {Production Examined by Bunnies : {{WeAreTheMusicMakers}}},
  timestamp = {2017-08-03T22:21:19Z},
  urldate = {2017-08-03},
  howpublished = {\url{https://www.reddit.com/r/WeAreTheMusicMakers/comments/29dpnb/production_examined_by_bunnies/}},
  groups = {mmt-thesis}
}

@inproceedings{raphael_music_2010,
  title = {Music plus One and Machine Learning},
  timestamp = {2017-08-03T22:55:44Z},
  urldate = {2017-08-03},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Machine Learning}} ({{ICML}}-10)},
  author = {Raphael, Christopher},
  year = {2010},
  pages = {21--28},
  file = {new_directions.pdf:/Volumes/Transcend/zotero/storage/BHCC3QJG/new_directions.pdf:application/pdf},
  groups = {mmt-thesis}
}

@article{ghisi_real-time_2016,
  title = {{{REAL}}-{{TIME CORPUS}}-{{BASED CONCATENATIVE SYNTHESIS FOR SYMBOLIC NOTATION}}},
  timestamp = {2017-08-04T09:19:37Z},
  urldate = {2017-08-04},
  author = {Ghisi, Daniele and Agon, Carlos},
  year = {2016},
  file = {01_Ghisi_tenor2016.pdf:/Volumes/Transcend/zotero/storage/2DAK9W77/01_Ghisi_tenor2016.pdf:application/pdf},
  groups = {mmt-thesis}
}

@misc{adenot_web_2017,
  title = {Web {{Audio API}} Performance and Debugging Notes},
  timestamp = {2017-08-04T15:02:35Z},
  urldate = {2017-08-04},
  howpublished = {\url{https://padenot.github.io/web-audio-perf/}},
  author = {Adenot, Paul},
  year = {2017},
  groups = {mmt-thesis}
}

@misc{kay_what_2017,
  title = {What Was It like to Be at {{Xerox PARC}} When {{Steve Jobs}} Visited? - {{Quora}}},
  timestamp = {2017-08-04T15:11:39Z},
  urldate = {2017-08-04},
  howpublished = {\url{https://www.quora.com/What-was-it-like-to-be-at-Xerox-PARC-when-Steve-Jobs-visited}},
  author = {Kay, Alan},
  year = {2017},
  groups = {mmt-thesis}
}


