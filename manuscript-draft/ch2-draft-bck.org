** Introduction
This chapter begins with a discussion on the dominant metaphors present in the modern DAW and expands on the earlier introduction to the topic. Some concrete examples are given to illuminate the issues and limitations that these metaphors impose on its users. This is followed up with a survey of legacy systems that take a graphical approach to their interface and can be conceptually framed with the metaphor of sketching.

** Dominant DAW metaphors
As has been asserted, analog studio metaphors of tape machines and hardware mixing desks dominate the UI approach to DAW interface design. Some other prevalent metaphors found is that of the /ou/, the /keyboard/ and the /score/ \cite{bell_journal_2015,levin_painterly_2000,adenot_web_2017,ableton_live_2017}. Clear examples of control panel metaphors can be found in plugin effects and present the user with banks of knobs and sliders that are often rendered as realistic imitations of their analog inspirations (figure fig:plugin-knobs-sliders).

** A compositional example
Rather than discussing the issues that can arise from the metaphors in the abstract, let us consider a compositional idea and how we might acheive this in a DAW. The idea is broken into the following compositional "recipe": 
1. Two notes of the same timbre are played together about an octave apart for a duration of 2 seconds.
2. The first note glissandos to the frequency of the second note and vice versa.
3. The first note starts with a small amount of vibrato the quickly dissipates.
4. The second note starts with no vibrato but adds a small amount as the note nears completion.
5. When these two notes end, the same pattern is repeated except this time with different timbres and frequencies.
6. This is repeated 3 more times with different timbres and frequencies to make complete this ten-second piece.

While this may seem like a contrived example this, in fact, constitutes a compositional technique called Klangfarbenmelodie that involves splitting a melodic line between intruments or timbre to create a timbre melody. The glissandos and altering of vibrato intensity constitute add further complexity and better illustrate some of the weaknesses inherent in DAW metaphors.
 
To achieve this in a DAW we have a few different options but a possible solution would be as follows:
1. Working with the multitrack tape metaphor we can create ten separate tracks to house two different versions of each timbre. Add a vibrato plugin effect to each of these by using a send or an insert effect. Two different tracks are needed for each of the timbres due to the fact that the two notes are played at the same time and both have different frequency and effect trajectories. If on the other hand they had the same effect modulations there would not need to be new tracks created.
2. Working with the piano roll metaphor, create a single note in each of these tracks setting each one to the desired fundamental frequency.
3. Now edit the pitch bend automation lane by clicking into the relevant dialog
3. Similarly, open the relevant dialog to edit the intensity of the vibrato effect 

At this point, we may have achieved what we set out to do. However, we now may want to tweak each of these elements to taste and perhaps add more material. An explosion in track count and overall complexity is inevitable. This can lead to a serious slowdown in workflow, a loss of flow and cognitive overload. A common technique to combat this complexity overload is to bounce the tracks and then continue working on these simpler artifacts (Duignan???). This, of course, negates a key advantage to working in a digital environment, the fine grained ability to freely change, tweak and undo. There are of course other tools in the DAW that may achieve this task more easily. For instance, a sampler may allow us to use different timbres on the same track and may work better in this case. We now have the extra task of exporting each of these samples in preparation for our composition work. Some other options present in many DAWS include aggregate instruments, multi-timbral instruments, and perhaps some midi routing options. This points to another problem that is often encountered when using DAWs, that of option dilemma. Some alternative environments to realising our contrived composition will now be considered.

MAX msp, music N, analytic thinking (system 1/system 2) John Cage, that flow guy.

A particular criticism of the DAW is the difficulty in maintaining and managing the editing of complex automation information.  Automation is the term given to the continuous altering of aspects of the sound and is usually represented in lanes separate to the primary note pitch information, as illustrated in figure fig:automation-lanes. It may be recorded in or drawn in by the producer. Difficulties can arise when multiple interacting lines of automation, such as pitch bends and filter changes, are being manipulated. A particularly clear example of this is the difficulty of representing "portamento time", the time it takes a note to slide from one to the next, as shown in figure fig:portamento. The visual results are unintuitive and not reflective of the audio results.

Duignan (2008) describes a similar problem in his study that monitored professional producers working in DAW environments (Duignan, 2008, p. 156). The particular problem identified by Duignan was that of processing one-off effects for single musical events. A number of convoluted processes were observed, including bouncing the affected portion to audio, duplicating the track, setting up a particular auxiliary for the effect and controlling the effect with automation. 

In these cases, the hierarchy imposed by the DAW gets in the way, where it could be modeled quite elegantly in a more open program such as the visual programming environment Cycling74’s Max Msp [ref to website]. This, unfortunately, raises the issue of analytic thinking versus creative thinking. <Give an understanding of these different modes of thinking, with refs, maybe Levin’s discussion>, 

From a creative perspective, John Cage advised against carrying out these tasks simultaneously "Don't try to create and analyse at the same time. They're different processes" (Popova, 2012). The need to explore alternative metaphors is clear. A description of a promising alternative metaphor, that of drawing/sketching will now be discussed.

** Sketching as an alternative metaphor
We shall now consider systems that use metaphors that are graphic nature. These are less common and if present less prominent in the DAW interface. As is pointed out by Levin (2002), the exploration of synchrony between audio and visuals is a practice going back centuries, being variously termed "ocular music, visual music, color music, or music for the eyes" (Levin, 2000). The twentieth-century technique of the optical soundtrack, however, brought these ideas to a new level of sophistication. The technique, which involved placing marks via photography or direct manipulation to specify audio properties, was explored by such luminaries as Oskar Fischinger, Norman McLaren and Daphne Oram. Oram's particular take on the technique will now be discussed as her system most closely resembles that of a piano roll.

*** Oramics
A primary motivating factor behind Daphne Oram's development of the Oramics machine was to bring more human-like qualities to the sounds generated by electronic means. The machine worked by playing back multiple lanes of film tape in unison, defining a monophonic series of notes as well as control signals to shape their timbre, pitch and amplitude. She details the thought process behind this in her hugely insightful and broad ranging journal style book, "An Individual Note" (???).

The aspects of the sound that she wishes to control are volume, duration, timbre, pitch, vibrato and reverb. In order to do this she describes a simple musical notation language based on the freehand drawing of lines combined with discrete symbols. The lines, which she describes as the analog control, are used to define volume envelopes. Interestingly, the default and preferred method for the parameters she wishes to control is the continuous line rather than discrete note symbols. For instance, she avoids the use of a static velocity per note and instead only specifies the use of a control envelope to change amplitude.

The discrete symbols, which she categorizes as digital control, are used to define individual pitches and are termed neumes. She highlights that notes should not remain static and, thusly, an analog control of each note is also specified. Similarly to amplitude and vibrato, timbre is also defined by the freehand drawing of lines and is something that with practice the "inner ear" can develop an intuition as the sonic results of different line shapes. It is Oram's belief that the hand drawn nature of the lines make the results slightly inaccurate and to some extent unpredictable but in this also lies the possibility of bringing more humanity to the cold and precise machines generating the electronic signal.

*** UPIC
The UPIC ("Unité polyagogique informatique du CEMAMU") was a graphic sound synthesis system that was designed by Iannis Xenakis and arose from his graphic approach to composition. His earliest work, "Metastasis", completed while under the tutelage of French composer Olivier Messiaen, was conceived using a graphic approach to describe trajectories and sound masses (figure fig:xenakis-metastatis). This approach has been attributed to his background in architecture, having worked in the studio of Le Corbusier. The UPIC was first conceived of in the seventies with the realisation of the first version in 1975 and its first public showcase in 1977. The work "Mycanae Alpha", composed in 1978 was the first work to use the system and was a  "nine-minute 38-second composition of dense and intense textures, of phase-shifting waveforms rich in harmonics that cascade, flutter, crash, and scream like sirens in a vast cosmological territory" \cite{tyranny_mycenae-alpha_2017}. 

This early version worked by drawing on a large digitizing graphics tablet which was interpreted by computer and converted into audio signals. The graphic approach to sound specification worked on a synthesis level by allowing the composer to draw and audition waveforms. Larger structures could be drawn in by switching to a "score" page and drawing lines, or "arcs" as they were denoted, on a pitch-time canvas. The final version of the application ran on personal computers and allowed for real-time interaction with a 64 oscillator synthesizer. At this stage, the input means had changed to a computer mouse but nevertheless retained the graphic approach of interaction. 

A primary goal of the UPIC project was that of pedagogy. Xenakis reasoned that the universality of sketching meant that it could provide an excellent teaching tool for a wide audience, even for young children (figure fig:xenakis-children). Another goal of the system was to encourage composer autonomy. At the time of its conception in the seventies, the technical barrier to entry into electronic music creation was very high and interfaces to help with this were rare or non-existent. Though the UPIC is not available to the general public currently, it has inspired a number of other systems that are available and will be considered in the next chapter. 

** A Golan Levin's AVES
Golan Levin created the interactive audio visual system, AVES, a series of audio visual installations in the late nineties and represented a landmark in the field of visual music. It is an attempt to move away from the diagrammatic approach to musical interfaces and to present an interface that is painterly in approach. Taking strong influence from visual artists such as Paul Klee, he presents a system that maps user input from a graphics tablet and mouse to visuals and to music. The intention is to create a strong visual correlation between the visuals and the music. A variety of approaches are taken to achieve this, all of them involving an algorithmic approach to one degree or another. For instance, in the piece "Aurora", he maps visuals of vast quantities of particles to a granulated sound synth sound source. He didn't take the approach of an exact mapping of visual particles to audio particles however and instead used a statistical control approach to approximate the correlation in between the visual and aural. (Levin, 2000)

For Levin, the digital pen input in combination with it's infinite variability represents an ideal instrument for creative expression in his digital temporal audio visual paintings. (???) The reason he gives for this is, similar to a musical instrument such as a violin, the pen is instantly knowable in that a child can pick it up and start creating marks but infinitely masterable through practice and hard work, and ultimately a vehicle for creative expression after a certain amount of mastery. A set of criteria that he and John Maeda arrived at to evaluate the success of their experiments was: is it instantly knowable, how long did you use it, how much of your personality can be expressed through it and, finally, with practice is it possible to improve using it. These ideas foreshadow much of the ideas of the Natural User Interface and echo principles in game design and music instrument design.

Levin's work is largely realtime and transitional in nature with gestures giving rise to visual and audio reactions that rise, fall and dissipate. A description that he uses of some of work is that of creating ripples in a pond. Therefore his work is very much geared towards an instrument like experience and is not concerned with the recording or visualization of the temporal unfolding of musical events as would be the function of compositional tools such as DAWs and musical notation. Indeed it is a conscious design decision to avoid such representations. Many of the principles and ideas of his work can, however, be applied in the context of a composition tool.

** William Coleman's sonicPainter
SonicPainter by William Coleman is a novel musical sequencer that seeks to address some of the shortcomings of traditional approaches to music sequencing found in commercial DAWs (Coleman, 2015). The focus of the line and node based interface (see figure) is to bring timbral shaping to the fore rather than being hidden away in miscellaneous automation lanes. The design takes influence from legacy musical systems, in particular, UPIC and incorporates ideas from visual music and embodied cognition.

Similarly to traditional sequencers, the x axis represents time and the y axis pitch. Note information is input via keyboard and mouse but more as an intermediary prototype stage. The default mode for input is to click to create a node and follow that with an additional click to continue to shape the note. The note can be ended by clicking a keyboard shortcut. By enabling the drawing notes as lines in this manner, the unfolding of the note can be explicitly represented visually. Other timbral aspects such as vibrato are represented by further visual manipulation of the line. For instance, an overlaid sine wave line indicates the timing and amplitude of the vibrato. In addition, the system allows for freehand input of notes.
Coleman recommends that the system could be further improved by multi-touch input, specific elements for the control of other synthesis techniques, time/pitch grid quantization, and further visual timbre feedback representations. Many of these recommendations will be addressed and explored in SonicSketch through a system built using the guidelines of NUI (natural user interface).

** Conclusion
While the dominant metaphors used in DAWs have their uses they can lead to limitations in the creative process particularly at the early stage of idea creation. More open system give too much power and impede the creative process.
